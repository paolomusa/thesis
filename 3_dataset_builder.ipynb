{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6813a1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing en-es: pairs_en_es_bootstrapped_noreliable.csv ===\n",
      "[en->es] Checking 1334 rows...\n",
      "  ... processed 50/1334 rows\n",
      "  ... processed 100/1334 rows\n",
      "  ... processed 150/1334 rows\n",
      "  ... processed 200/1334 rows\n",
      "  ... processed 250/1334 rows\n",
      "  ... processed 300/1334 rows\n",
      "  ... processed 350/1334 rows\n",
      "  ... processed 400/1334 rows\n",
      "  ... processed 450/1334 rows\n",
      "  ... processed 500/1334 rows\n",
      "  ... processed 550/1334 rows\n",
      "  ... processed 600/1334 rows\n",
      "  ... processed 650/1334 rows\n",
      "  ... processed 700/1334 rows\n",
      "  ... processed 750/1334 rows\n",
      "  ... processed 800/1334 rows\n",
      "  ... processed 850/1334 rows\n",
      "  ... processed 900/1334 rows\n",
      "  ... processed 950/1334 rows\n",
      "  ... processed 1000/1334 rows\n",
      "  ... processed 1050/1334 rows\n",
      "  ... processed 1100/1334 rows\n",
      "  ... processed 1150/1334 rows\n",
      "  ... processed 1200/1334 rows\n",
      "  ... processed 1250/1334 rows\n",
      "  ... processed 1300/1334 rows\n",
      "  ... processed 1334/1334 rows\n",
      "[SAVE] en-es: 161/1334 matches → .\\pairs_en_es_bootstrapped_noreliable_matches.csv\n",
      "\n",
      "=== Processing en-it: pairs_en_it_bootstrapped_noreliable.csv ===\n",
      "[en->it] Checking 969 rows...\n",
      "  ... processed 50/969 rows\n",
      "  ... processed 100/969 rows\n",
      "  ... processed 150/969 rows\n",
      "  ... processed 200/969 rows\n",
      "  ... processed 250/969 rows\n",
      "  ... processed 300/969 rows\n",
      "  ... processed 350/969 rows\n",
      "  ... processed 400/969 rows\n",
      "  ... processed 450/969 rows\n",
      "  ... processed 500/969 rows\n",
      "  ... processed 550/969 rows\n",
      "  ... processed 600/969 rows\n",
      "  ... processed 650/969 rows\n",
      "  ... processed 700/969 rows\n",
      "  ... processed 750/969 rows\n",
      "  ... processed 800/969 rows\n",
      "  ... processed 850/969 rows\n",
      "  ... processed 900/969 rows\n",
      "  ... processed 950/969 rows\n",
      "  ... processed 969/969 rows\n",
      "[SAVE] en-it: 137/969 matches → .\\pairs_en_it_bootstrapped_noreliable_matches.csv\n",
      "\n",
      "=== Processing en-pt: pairs_en_pt_bootstrapped_noreliable.csv ===\n",
      "[en->pt-br] Checking 1245 rows...\n",
      "  ... processed 50/1245 rows\n",
      "  ... processed 100/1245 rows\n",
      "  ... processed 150/1245 rows\n",
      "  ... processed 200/1245 rows\n",
      "  ... processed 250/1245 rows\n",
      "  ... processed 300/1245 rows\n",
      "  ... processed 350/1245 rows\n",
      "  ... processed 400/1245 rows\n",
      "  ... processed 450/1245 rows\n",
      "  ... processed 500/1245 rows\n",
      "  ... processed 550/1245 rows\n",
      "  ... processed 600/1245 rows\n",
      "  ... processed 650/1245 rows\n",
      "  ... processed 700/1245 rows\n",
      "  ... processed 750/1245 rows\n",
      "  ... processed 800/1245 rows\n",
      "  ... processed 850/1245 rows\n",
      "  ... processed 900/1245 rows\n",
      "  ... processed 950/1245 rows\n",
      "  ... processed 1000/1245 rows\n",
      "  ... processed 1050/1245 rows\n",
      "  ... processed 1100/1245 rows\n",
      "  ... processed 1150/1245 rows\n",
      "  ... processed 1200/1245 rows\n",
      "  ... processed 1245/1245 rows\n",
      "[SAVE] en-pt: 142/1245 matches → .\\pairs_en_pt_bootstrapped_noreliable_matches.csv\n",
      "\n",
      "=== Summary of matches ===\n",
      " pair  input_rows  matched_rows                                       output_file\n",
      "en-es        1334           161 .\\pairs_en_es_bootstrapped_noreliable_matches.csv\n",
      "en-it         969           137 .\\pairs_en_it_bootstrapped_noreliable_matches.csv\n",
      "en-pt        1245           142 .\\pairs_en_pt_bootstrapped_noreliable_matches.csv\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os, json, time, unicodedata\n",
    "from typing import List, Tuple\n",
    "from functools import lru_cache\n",
    "from urllib.parse import quote\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "KAIIKI_BASE = \"https://kaikki.org/dictionary\"\n",
    "LANG_NAME = {\n",
    "    \"en\": \"English\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"pt-br\": \"Portuguese\",\n",
    "}\n",
    "SUPPORTED = {\n",
    "    (\"en\",\"es\"),(\"es\",\"en\"),\n",
    "    (\"en\",\"it\"),(\"it\",\"en\"),\n",
    "    (\"en\",\"pt\"),(\"pt\",\"en\"),\n",
    "    (\"en\",\"pt-br\"),(\"pt-br\",\"en\"),\n",
    "}\n",
    "\n",
    "def _normalize_lang(code: str) -> str:\n",
    "    code = code.lower()\n",
    "    if code in (\"pt_br\",\"ptbr\",\"pt-bra\",\"pt-brazil\"):\n",
    "        return \"pt-br\"\n",
    "    if code not in LANG_NAME:\n",
    "        raise ValueError(f\"Unsupported language code: {code}\")\n",
    "    return code\n",
    "\n",
    "def _http_session() -> requests.Session:\n",
    "    s = requests.Session()\n",
    "    retries = Retry(\n",
    "        total=3, backoff_factor=0.35,\n",
    "        status_forcelist=(429, 500, 502, 503, 504),\n",
    "        allowed_methods=frozenset([\"GET\"]),\n",
    "    )\n",
    "    s.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "    s.headers.update({\"User-Agent\": \"lemma-translation-check/kaikki-1.2\"})\n",
    "    return s\n",
    "SESSION = _http_session()\n",
    "\n",
    "def strip_diacritics(s: str) -> str:\n",
    "    if s is None: return \"\"\n",
    "    s = s.casefold()\n",
    "    return \"\".join(ch for ch in unicodedata.normalize(\"NFD\", s) if unicodedata.category(ch) != \"Mn\")\n",
    "\n",
    "def _kaikki_sharded_paths(word: str, lang_name: str) -> List[str]:\n",
    "    p1 = word[:1] or word\n",
    "    p2 = word[:2] or word\n",
    "    q_lang, q_p1, q_p2, q_word = map(quote, (lang_name, p1, p2, word))\n",
    "    return [\n",
    "        f\"{KAIIKI_BASE}/{q_lang}/meaning/{q_p1}/{q_p2}/{q_word}.jsonl\",\n",
    "        f\"{KAIIKI_BASE}/{q_lang}/meaning/{q_p1}/{q_p2}/{q_word}.json\",\n",
    "        f\"{KAIIKI_BASE}/{q_lang}/meaning/{q_word}.json\",\n",
    "        f\"{KAIIKI_BASE}/{q_lang}/meaning/{q_p1}/{q_p2}/{q_word}.html\",\n",
    "    ]\n",
    "\n",
    "@lru_cache(maxsize=20000)\n",
    "def fetch_kaikki_entries(word: str, lang_code: str) -> List[dict]:\n",
    "    lang_code = _normalize_lang(lang_code)\n",
    "    lang_name = LANG_NAME[lang_code]\n",
    "    for url in _kaikki_sharded_paths(word, lang_name):\n",
    "        try:\n",
    "            r = SESSION.get(url, timeout=12)\n",
    "        except requests.RequestException:\n",
    "            continue\n",
    "\n",
    "        if r.status_code != 200 or not r.text:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        if url.endswith(\".jsonl\"):\n",
    "            try:\n",
    "                return [json.loads(line) for line in r.text.splitlines() if line.strip()]\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        if url.endswith(\".json\"):\n",
    "            try:\n",
    "                data = r.json()\n",
    "                if isinstance(data, dict):\n",
    "                    data = [data]\n",
    "                return data or []\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        if url.endswith(\".html\"):\n",
    "            try:\n",
    "                soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                entries: List[dict] = []\n",
    "                for pre in soup.find_all(\"pre\"):\n",
    "                    txt = pre.get_text(\"\\n\", strip=True)\n",
    "                    if txt.startswith(\"{\") and txt.endswith(\"}\"):\n",
    "                        try:\n",
    "                            obj = json.loads(txt)\n",
    "                            if isinstance(obj, dict): entries.append(obj)\n",
    "                            elif isinstance(obj, list): entries.extend(obj)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                if entries:\n",
    "                    return entries\n",
    "            except Exception:\n",
    "                continue\n",
    "    return []\n",
    "\n",
    "def _collect_translations(entries: List[dict], target_lang_name: str, prefer_brazilian: bool | None = None) -> List[str]:\n",
    "    def grab(prefer: bool | None) -> List[str]:\n",
    "        out: List[str] = []\n",
    "        for e in entries:\n",
    "            blocks = []\n",
    "            if \"translations\" in e: blocks.extend(e.get(\"translations\") or [])\n",
    "            for sense in e.get(\"senses\", []):\n",
    "                blocks.extend(sense.get(\"translations\") or [])\n",
    "            for tr in blocks:\n",
    "                if (tr.get(\"lang\") or \"\").strip() != target_lang_name:\n",
    "                    continue\n",
    "                w = (tr.get(\"word\") or \"\").strip()\n",
    "                if not w: continue\n",
    "                tags = [t.lower() for t in (tr.get(\"tags\") or [])]\n",
    "                is_brazil = any(\"brazil\" in t for t in tags)\n",
    "                if prefer is True and not is_brazil:  continue\n",
    "                if prefer is False and is_brazil:      continue\n",
    "                out.append(w)\n",
    "        \n",
    "        seen = set()\n",
    "        deduped = []\n",
    "        for w in out:\n",
    "            if w not in seen:\n",
    "                seen.add(w)\n",
    "                deduped.append(w)\n",
    "        return deduped\n",
    "    primary = grab(prefer_brazilian)\n",
    "    return primary if primary else grab(None)\n",
    "\n",
    "def get_translation_candidates(src_word: str, src_lang: str, tgt_lang: str) -> List[str]:\n",
    "    src_lang = _normalize_lang(src_lang)\n",
    "    tgt_lang = _normalize_lang(tgt_lang)\n",
    "    entries = fetch_kaikki_entries(src_word, src_lang)\n",
    "    tgt_lang_name = LANG_NAME[tgt_lang]\n",
    "    prefer_brazilian = True if tgt_lang == \"pt-br\" else None\n",
    "    return _collect_translations(entries, tgt_lang_name, prefer_brazilian=prefer_brazilian)\n",
    "\n",
    "def mutual_translation(src_word: str, tgt_word: str, src_lang: str, tgt_lang: str) -> Tuple[bool,bool,List[str],List[str]]:\n",
    "    s2t = get_translation_candidates(src_word, src_lang, tgt_lang)\n",
    "    t2s = get_translation_candidates(tgt_word, tgt_lang, src_lang)\n",
    "    tgt_norm = strip_diacritics(tgt_word)\n",
    "    src_norm = strip_diacritics(src_word)\n",
    "    src_in_tgt = any(strip_diacritics(x) == tgt_norm for x in s2t)\n",
    "    tgt_in_src = any(strip_diacritics(x) == src_norm for x in t2s)\n",
    "    return src_in_tgt, tgt_in_src, s2t, t2s\n",
    "\n",
    "def check_df_translations_kaikki(\n",
    "    df: pd.DataFrame, src_lang: str, tgt_lang: str,\n",
    "    src_col: str = \"src_lemma\", tgt_col: str = \"tgt_lemma\"\n",
    ") -> pd.DataFrame:\n",
    "    src_lang_n = _normalize_lang(src_lang)\n",
    "    tgt_lang_n = _normalize_lang(tgt_lang)\n",
    "    if (src_lang_n, tgt_lang_n) not in SUPPORTED:\n",
    "        raise ValueError(f\"Unsupported pair {src_lang_n}-{tgt_lang_n}\")\n",
    "    rows = []\n",
    "    \n",
    "    N = len(df)\n",
    "    print(f\"[{src_lang_n}->{tgt_lang_n}] Checking {N} rows...\")\n",
    "    for i, row in enumerate(df.itertuples(index=False), 1):\n",
    "        s = str(getattr(row, src_col)).strip()\n",
    "        t = str(getattr(row, tgt_col)).strip()\n",
    "        try:\n",
    "            s_in_t, t_in_s, s2t, t2s = mutual_translation(s, t, src_lang_n, tgt_lang_n)\n",
    "        except requests.RequestException:\n",
    "            s_in_t = t_in_s = False; s2t = t2s = []\n",
    "        rows.append({\n",
    "            src_col: s, tgt_col: t,\n",
    "            \"src_in_tgt\": bool(s_in_t),\n",
    "            \"tgt_in_src\": bool(t_in_s),\n",
    "            \"src_to_tgt_candidates\": s2t,\n",
    "            \"tgt_to_src_candidates\": t2s,\n",
    "        })\n",
    "        \n",
    "        if i % 50 == 0 or i == N:\n",
    "            print(f\"  ... processed {i}/{N} rows\")\n",
    "    out = pd.DataFrame(rows)\n",
    "    \n",
    "    out[\"match\"] = out[\"src_in_tgt\"] | out[\"tgt_in_src\"]\n",
    "    out[\"match_evidence\"] = out.apply(\n",
    "        lambda r: \"both\" if (r[\"src_in_tgt\"] and r[\"tgt_in_src\"]) else (\"src->tgt\" if r[\"src_in_tgt\"] else (\"tgt->src\" if r[\"tgt_in_src\"] else \"\")),\n",
    "        axis=1\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "inputs = OrderedDict({\n",
    "    \"en-es\": \"pairs_en_es_bootstrapped_noreliable.csv\",\n",
    "    \"en-it\": \"pairs_en_it_bootstrapped_noreliable.csv\",\n",
    "    \"en-pt\": \"pairs_en_pt_bootstrapped_noreliable.csv\",\n",
    "})\n",
    "\n",
    "\n",
    "pair_langs = {\n",
    "    \"en-es\": (\"en\",\"es\"),\n",
    "    \"en-it\": (\"en\",\"it\"),\n",
    "    \"en-pt\": (\"en\",\"pt-br\"),\n",
    "}\n",
    "\n",
    "base_dir = \".\"\n",
    "summary_rows = []\n",
    "\n",
    "for pair, filename in inputs.items():\n",
    "    path = os.path.join(base_dir, filename)\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[SKIP] {pair}: file not found: {path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n=== Processing {pair}: {filename} ===\")\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    \n",
    "    if \"src_lemma\" not in df.columns or \"tgt_lemma\" not in df.columns:\n",
    "        raise ValueError(f\"{filename} must contain 'src_lemma' and 'tgt_lemma' columns.\")\n",
    "\n",
    "    src_lang, tgt_lang = pair_langs[pair]\n",
    "    checked = check_df_translations_kaikki(df, src_lang, tgt_lang)\n",
    "\n",
    "    \n",
    "    out_path = os.path.join(base_dir, filename.replace(\".csv\", \"_matches.csv\"))\n",
    "    matches = df.loc[checked[\"match\"]].copy()\n",
    "    matches.to_csv(out_path, index=False)\n",
    "    print(f\"[SAVE] {pair}: {len(matches)}/{len(checked)} matches → {out_path}\")\n",
    "\n",
    "    \n",
    "    summary_rows.append({\n",
    "        \"pair\": pair,\n",
    "        \"input_rows\": len(df),\n",
    "        \"matched_rows\": len(matches),\n",
    "        \"output_file\": out_path,\n",
    "    })\n",
    "\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(\"pair\")\n",
    "print(\"\\n=== Summary of matches ===\")\n",
    "print(summary_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def dedupe_matches_file(path_in: str, path_out: str | None = None) -> pd.DataFrame:\n",
    "    \n",
    "    if path_out is None:\n",
    "        path_out = path_in.replace(\"_matches.csv\", \"_matches_dedup.csv\")\n",
    "\n",
    "    print(f\"[LOAD] {path_in}\")\n",
    "    df = pd.read_csv(path_in)\n",
    "\n",
    "    \n",
    "    na_like = {\"N/A\": pd.NA, \"NA\": pd.NA, \"na\": pd.NA, \"NaN\": pd.NA, \"None\": pd.NA, \"\": pd.NA}\n",
    "    df_na = df.replace(na_like)\n",
    "\n",
    "    \n",
    "    df[\"_na_count\"] = df_na.isna().sum(axis=1)\n",
    "\n",
    "    \n",
    "    if not {\"src_lemma\", \"tgt_lemma\"}.issubset(df.columns):\n",
    "        raise ValueError(\"Input must contain 'src_lemma' and 'tgt_lemma' columns.\")\n",
    "\n",
    "    \n",
    "    best_idx = df.groupby([\"src_lemma\", \"tgt_lemma\"])[\"_na_count\"].idxmin()\n",
    "\n",
    "    dedup = (\n",
    "        df.loc[best_idx]\n",
    "          .drop(columns=[\"_na_count\"])\n",
    "          .sort_values([\"src_lemma\", \"tgt_lemma\"])\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    dedup.to_csv(path_out, index=False)\n",
    "    print(f\"[SAVE] {len(dedup)} rows (from {len(df)}) → {path_out}\")\n",
    "    return dedup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d413008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] pairs_en_es_bootstrapped_noreliable_matches.csv\n",
      "[SAVE] 132 rows (from 161) → pairs_en_es_bootstrapped_noreliable_matches_dedup.csv\n",
      "[LOAD] pairs_en_it_bootstrapped_noreliable_matches.csv\n",
      "[SAVE] 120 rows (from 137) → pairs_en_it_bootstrapped_noreliable_matches_dedup.csv\n",
      "[LOAD] pairs_en_pt_bootstrapped_noreliable_matches.csv\n",
      "[SAVE] 122 rows (from 142) → pairs_en_pt_bootstrapped_noreliable_matches_dedup.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "for path in sorted(glob(\"pairs_en_*_bootstrapped_noreliable_matches.csv\")):\n",
    "    try:\n",
    "        dedupe_matches_file(path)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8e303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for inputs under: c:\\Users\\paolo\\OneDrive - Tilburg University\\S2. Thesis\\DUOLINWORK\n",
      "Found dedup files   : ['pairs_en_es_bootstrapped_noreliable_matches_dedup.csv', 'pairs_en_it_bootstrapped_noreliable_matches_dedup.csv', 'pairs_en_pt_bootstrapped_noreliable_matches_dedup.csv']\n",
      "Found reliable files: ['reliable_pairs_en_es.csv', 'reliable_pairs_en_es_conflicts.csv', 'reliable_pairs_en_es_enriched.csv', 'reliable_pairs_en_es_only_new_from_v2.csv', 'reliable_pairs_en_it.csv', 'reliable_pairs_en_it_conflicts.csv', 'reliable_pairs_en_it_enriched.csv', 'reliable_pairs_en_it_only_new_from_v2.csv', 'reliable_pairs_en_pt.csv', 'reliable_pairs_en_pt_conflicts.csv', 'reliable_pairs_en_pt_enriched.csv', 'reliable_pairs_en_pt_only_new_from_v2.csv']\n",
      "\n",
      "=== ES ===\n",
      "Looking for:\n",
      "  dedup    : .\\pairs_en_es_bootstrapped_noreliable_matches_dedup.csv  (found)\n",
      "  reliable : .\\reliable_pairs_en_es.csv  (found)\n",
      " -> overlap_pairs: 57 | dedup_only: 75 | reliable_only: 1207 | final_rows: 1339\n",
      " -> wrote en_es_prefrel_union.csv\n",
      "\n",
      "=== IT ===\n",
      "Looking for:\n",
      "  dedup    : .\\pairs_en_it_bootstrapped_noreliable_matches_dedup.csv  (found)\n",
      "  reliable : .\\reliable_pairs_en_it.csv  (found)\n",
      " -> overlap_pairs: 49 | dedup_only: 71 | reliable_only: 842 | final_rows: 962\n",
      " -> wrote en_it_prefrel_union.csv\n",
      "\n",
      "=== PT ===\n",
      "Looking for:\n",
      "  dedup    : .\\pairs_en_pt_bootstrapped_noreliable_matches_dedup.csv  (found)\n",
      "  reliable : .\\reliable_pairs_en_pt.csv  (found)\n",
      " -> overlap_pairs: 52 | dedup_only: 70 | reliable_only: 1028 | final_rows: 1150\n",
      " -> wrote en_pt_prefrel_union.csv\n",
      "\n",
      "=== Summary ===\n",
      "lang  dedup_only  reliable_only  overlap_pairs  final_rows             output_file\n",
      "  es          75           1207             57        1339 en_es_prefrel_union.csv\n",
      "  it          71            842             49         962 en_it_prefrel_union.csv\n",
      "  pt          70           1028             52        1150 en_pt_prefrel_union.csv\n",
      "\n",
      "Saved summary → .\\prefrel_union_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "BASE  = \".\"   \n",
    "KEY   = [\"src_lemma\", \"tgt_lemma\"]\n",
    "LANGS = [\"es\", \"it\", \"pt\"]  \n",
    "\n",
    "\n",
    "RELIABLE_PATTERNS = {\n",
    "    \"es\": [\"reliable_pairs_en_es.csv\"],\n",
    "    \"it\": [\"reliable_pairs_en_it.csv\"],\n",
    "    \"pt\": [\"reliable_pairs_en_pt.csv\", \"reliable_pairs_en_pt-br.csv\"],\n",
    "    \"pt-br\": [\"reliable_pairs_en_pt-br.csv\", \"reliable_pairs_en_pt.csv\"],\n",
    "}\n",
    "\n",
    "def find_first_existing(paths):\n",
    "    for p in paths:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def load_csv(path):\n",
    "    if path and os.path.exists(path):\n",
    "        return pd.read_csv(path)\n",
    "    return None\n",
    "\n",
    "def coalesce_columns_with_keys(merged, reliable_cols, dedup_cols, key_cols):\n",
    "    out = {}\n",
    "    \n",
    "    for k in key_cols:\n",
    "        if k not in merged.columns:\n",
    "            raise KeyError(f\"Key column {k!r} missing from merged DataFrame.\")\n",
    "        out[k] = merged[k]\n",
    "    \n",
    "    names = (set(reliable_cols) | set(dedup_cols)) - set(key_cols)\n",
    "    for name in names:\n",
    "        pref = name + \"_pref\"  \n",
    "        fb   = name + \"_fb\"    \n",
    "        s_pref = merged[pref] if pref in merged.columns else None\n",
    "        s_fb   = merged[fb]   if fb   in merged.columns else None\n",
    "        if s_pref is not None and s_fb is not None:\n",
    "            out[name] = s_pref.combine_first(s_fb)\n",
    "        elif s_pref is not None:\n",
    "            out[name] = s_pref\n",
    "        elif s_fb is not None:\n",
    "            out[name] = s_fb\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "def process_lang(xx):\n",
    "    dedup_path = os.path.join(BASE, f\"pairs_en_{xx}_bootstrapped_noreliable_matches_dedup.csv\")\n",
    "    reliable_candidates = [os.path.join(BASE, name) for name in RELIABLE_PATTERNS.get(xx, [])]\n",
    "    reliable_path = find_first_existing(reliable_candidates)\n",
    "\n",
    "    print(f\"\\n=== {xx.upper()} ===\")\n",
    "    print(f\"Looking for:\")\n",
    "    print(f\"  dedup    : {dedup_path}  ({'found' if os.path.exists(dedup_path) else 'missing'})\")\n",
    "    if reliable_path:\n",
    "        print(f\"  reliable : {reliable_path}  (found)\")\n",
    "    else:\n",
    "        print(f\"  reliable : {', '.join(reliable_candidates) or '(none)'}  (missing)\")\n",
    "\n",
    "    dedup = load_csv(dedup_path)\n",
    "    reli  = load_csv(reliable_path)\n",
    "\n",
    "    out_path = os.path.join(BASE, f\"en_{xx}_prefrel_union.csv\")\n",
    "\n",
    "    # Edge cases\n",
    "    if dedup is None and reli is None:\n",
    "        print(\" -> SKIP: no inputs.\")\n",
    "        return {\"lang\": xx, \"dedup_only\": 0, \"reliable_only\": 0, \"overlap_pairs\": 0, \"final_rows\": 0, \"output_file\": \"\"}\n",
    "\n",
    "    if dedup is None:\n",
    "        out_df = reli.sort_values(KEY).reset_index(drop=True)\n",
    "        out_df.to_csv(out_path, index=False)\n",
    "        print(f\" -> ONLY reliable: wrote {len(out_df)} rows → {os.path.basename(out_path)}\")\n",
    "        return {\"lang\": xx, \"dedup_only\": 0, \"reliable_only\": len(out_df), \"overlap_pairs\": 0, \"final_rows\": len(out_df), \"output_file\": os.path.basename(out_path)}\n",
    "\n",
    "    if reli is None:\n",
    "        out_df = dedup.sort_values(KEY).reset_index(drop=True)\n",
    "        out_df.to_csv(out_path, index=False)\n",
    "        print(f\" -> ONLY dedup: wrote {len(out_df)} rows → {os.path.basename(out_path)}\")\n",
    "        return {\"lang\": xx, \"dedup_only\": len(out_df), \"reliable_only\": 0, \"overlap_pairs\": 0, \"final_rows\": len(out_df), \"output_file\": os.path.basename(out_path)}\n",
    "\n",
    "    # Sanity on keys\n",
    "    if not set(KEY).issubset(dedup.columns) or not set(KEY).issubset(reli.columns):\n",
    "        raise ValueError(f\"Both inputs must contain key columns: {', '.join(KEY)}\")\n",
    "\n",
    "    merged = dedup.merge(reli, on=KEY, how=\"outer\", suffixes=(\"_fb\", \"_pref\"), indicator=True)\n",
    "\n",
    "    n_left_only  = int((merged[\"_merge\"] == \"left_only\").sum())   \n",
    "    n_right_only = int((merged[\"_merge\"] == \"right_only\").sum())  \n",
    "    n_both       = int((merged[\"_merge\"] == \"both\").sum())        \n",
    "\n",
    "    out_df = coalesce_columns_with_keys(\n",
    "        merged,\n",
    "        reliable_cols=list(reli.columns),\n",
    "        dedup_cols=list(dedup.columns),\n",
    "        key_cols=KEY\n",
    "    ).sort_values(KEY).reset_index(drop=True)\n",
    "\n",
    "    out_df.to_csv(out_path, index=False)\n",
    "    print(f\" -> overlap_pairs: {n_both} | dedup_only: {n_left_only} | reliable_only: {n_right_only} | final_rows: {len(out_df)}\")\n",
    "    print(f\" -> wrote {os.path.basename(out_path)}\")\n",
    "\n",
    "    return {\"lang\": xx, \"dedup_only\": n_left_only, \"reliable_only\": n_right_only, \"overlap_pairs\": n_both, \"final_rows\": len(out_df), \"output_file\": os.path.basename(out_path)}\n",
    "\n",
    "\n",
    "print(\"Scanning for inputs under:\", os.path.abspath(BASE))\n",
    "found_dedup = sorted(glob(os.path.join(BASE, \"pairs_en_*_bootstrapped_noreliable_matches_dedup.csv\")))\n",
    "found_rel   = sorted(glob(os.path.join(BASE, \"reliable_pairs_en_*.csv\")))\n",
    "print(\"Found dedup files   :\", [os.path.basename(p) for p in found_dedup] or \"(none)\")\n",
    "print(\"Found reliable files:\", [os.path.basename(p) for p in found_rel] or \"(none)\")\n",
    "\n",
    "\n",
    "summary = [process_lang(xx) for xx in LANGS]\n",
    "summary_df = pd.DataFrame(summary).sort_values(\"lang\")\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "\n",
    "summary_df.to_csv(os.path.join(BASE, \"prefrel_union_summary.csv\"), index=False)\n",
    "print(\"\\nSaved summary →\", os.path.join(BASE, \"prefrel_union_summary.csv\"))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b7fe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: en_es_prefrel_union.csv\n",
      "  -> reordered (10 columns), saved back to en_es_prefrel_union.csv\n",
      "Processing: en_it_prefrel_union.csv\n",
      "  -> reordered (10 columns), saved back to en_it_prefrel_union.csv\n",
      "Processing: en_pt_prefrel_union.csv\n",
      "  -> reordered (10 columns), saved back to en_pt_prefrel_union.csv\n",
      "✅ Done reordering all en_xx_prefrel_union.csv files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "BASE = \".\"\n",
    "pattern = os.path.join(BASE, \"en_*_prefrel_union.csv\")\n",
    "\n",
    "\n",
    "FIRST_COLS = [\"src_lemma\", \"tgt_lemma\", \"src_pos\", \"tgt_pos\", \"score\", \"quality\"]\n",
    "\n",
    "for path in sorted(glob(pattern)):\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"Processing: {os.path.basename(path)}\")\n",
    "\n",
    "    \n",
    "    first_present = [c for c in FIRST_COLS if c in df.columns]\n",
    "\n",
    "    \n",
    "    remaining = [c for c in df.columns if c not in first_present]\n",
    "\n",
    "    new_order = first_present + remaining\n",
    "    df = df[new_order]\n",
    "\n",
    "    \n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"  -> reordered ({len(df.columns)} columns), saved back to {os.path.basename(path)}\")\n",
    "\n",
    "print(\"✅ Done reordering all en_xx_prefrel_union.csv files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e4335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ES =====\n",
      "[INFO] Prefrel file: .\\en_es_prefrel_union.csv\n",
      "[INFO] Duo path    : .\\duo.csv\n",
      "[DUO] Building lemma map from duo.csv for combos [('en', 'es'), ('es', 'en')]\n",
      "  [DUO] Chunk 1 done: total_rows=200,000, kept=151,970, distinct_lemmas=2,457\n",
      "  [DUO] Chunk 2 done: total_rows=400,000, kept=311,008, distinct_lemmas=2,689\n",
      "  [DUO] Chunk 3 done: total_rows=600,000, kept=456,483, distinct_lemmas=2,872\n",
      "  [DUO] Chunk 4 done: total_rows=800,000, kept=601,445, distinct_lemmas=2,920\n",
      "  [DUO] Chunk 5 done: total_rows=1,000,000, kept=751,140, distinct_lemmas=2,959\n",
      "  [DUO] Chunk 6 done: total_rows=1,200,000, kept=915,001, distinct_lemmas=2,974\n",
      "  [DUO] Chunk 7 done: total_rows=1,400,000, kept=1,053,999, distinct_lemmas=2,994\n",
      "  [DUO] Chunk 8 done: total_rows=1,600,000, kept=1,198,277, distinct_lemmas=3,025\n",
      "  [DUO] Chunk 9 done: total_rows=1,800,000, kept=1,345,409, distinct_lemmas=3,028\n",
      "  [DUO] Chunk 10 done: total_rows=2,000,000, kept=1,496,855, distinct_lemmas=3,042\n",
      "  [DUO] Chunk 11 done: total_rows=2,200,000, kept=1,632,169, distinct_lemmas=3,050\n",
      "  [DUO] Chunk 12 done: total_rows=2,400,000, kept=1,776,567, distinct_lemmas=3,054\n",
      "  [DUO] Chunk 13 done: total_rows=2,600,000, kept=1,924,303, distinct_lemmas=3,055\n",
      "  [DUO] Chunk 14 done: total_rows=2,800,000, kept=2,083,048, distinct_lemmas=3,060\n",
      "  [DUO] Chunk 15 done: total_rows=3,000,000, kept=2,225,787, distinct_lemmas=3,066\n",
      "  [DUO] Chunk 16 done: total_rows=3,200,000, kept=2,369,643, distinct_lemmas=3,067\n",
      "  [DUO] Chunk 17 done: total_rows=3,400,000, kept=2,515,968, distinct_lemmas=3,068\n",
      "  [DUO] Chunk 18 done: total_rows=3,600,000, kept=2,676,198, distinct_lemmas=3,070\n",
      "  [DUO] Chunk 19 done: total_rows=3,800,000, kept=2,813,039, distinct_lemmas=3,071\n",
      "  [DUO] Chunk 20 done: total_rows=4,000,000, kept=2,956,877, distinct_lemmas=3,071\n",
      "  [DUO] Chunk 21 done: total_rows=4,200,000, kept=3,102,291, distinct_lemmas=3,072\n",
      "  [DUO] Chunk 22 done: total_rows=4,400,000, kept=3,259,091, distinct_lemmas=3,075\n",
      "  [DUO] Chunk 23 done: total_rows=4,600,000, kept=3,400,956, distinct_lemmas=3,076\n",
      "  [DUO] Chunk 24 done: total_rows=4,800,000, kept=3,542,875, distinct_lemmas=3,076\n",
      "  [DUO] Chunk 25 done: total_rows=5,000,000, kept=3,691,274, distinct_lemmas=3,077\n",
      "  [DUO] Chunk 26 done: total_rows=5,200,000, kept=3,841,276, distinct_lemmas=3,077\n",
      "  [DUO] Chunk 27 done: total_rows=5,400,000, kept=4,001,347, distinct_lemmas=3,078\n",
      "  [DUO] Chunk 28 done: total_rows=5,600,000, kept=4,136,656, distinct_lemmas=3,081\n",
      "  [DUO] Chunk 29 done: total_rows=5,800,000, kept=4,282,939, distinct_lemmas=3,081\n",
      "  [DUO] Chunk 30 done: total_rows=6,000,000, kept=4,435,658, distinct_lemmas=3,081\n",
      "  [DUO] Chunk 31 done: total_rows=6,200,000, kept=4,593,997, distinct_lemmas=3,082\n",
      "  [DUO] Chunk 32 done: total_rows=6,400,000, kept=4,731,663, distinct_lemmas=3,082\n",
      "  [DUO] Chunk 33 done: total_rows=6,600,000, kept=4,879,386, distinct_lemmas=3,083\n",
      "  [DUO] Chunk 34 done: total_rows=6,800,000, kept=5,028,846, distinct_lemmas=3,083\n",
      "  [DUO] Chunk 35 done: total_rows=7,000,000, kept=5,185,002, distinct_lemmas=3,083\n",
      "  [DUO] Chunk 36 done: total_rows=7,200,000, kept=5,323,790, distinct_lemmas=3,085\n",
      "  [DUO] Chunk 37 done: total_rows=7,400,000, kept=5,469,755, distinct_lemmas=3,085\n",
      "  [DUO] Chunk 38 done: total_rows=7,600,000, kept=5,620,257, distinct_lemmas=3,085\n",
      "  [DUO] Chunk 39 done: total_rows=7,800,000, kept=5,767,466, distinct_lemmas=3,085\n",
      "  [DUO] Chunk 40 done: total_rows=8,000,000, kept=5,908,784, distinct_lemmas=3,086\n",
      "  [DUO] Chunk 41 done: total_rows=8,200,000, kept=6,056,912, distinct_lemmas=3,086\n",
      "  [DUO] Chunk 42 done: total_rows=8,400,000, kept=6,211,761, distinct_lemmas=3,086\n",
      "  [DUO] Chunk 43 done: total_rows=8,600,000, kept=6,360,240, distinct_lemmas=3,086\n",
      "  [DUO] Chunk 44 done: total_rows=8,800,000, kept=6,505,737, distinct_lemmas=3,087\n",
      "  [DUO] Chunk 45 done: total_rows=9,000,000, kept=6,655,275, distinct_lemmas=3,088\n",
      "  [DUO] Chunk 46 done: total_rows=9,200,000, kept=6,809,685, distinct_lemmas=3,088\n",
      "  [DUO] Chunk 47 done: total_rows=9,400,000, kept=6,961,606, distinct_lemmas=3,088\n",
      "  [DUO] Chunk 48 done: total_rows=9,527,895, kept=7,048,868, distinct_lemmas=3,088\n",
      "[DUO] Finished. Total kept rows=7,048,868, distinct lemmas=3,088\n",
      "[ES] Enriching 1339 rows ...\n",
      "  [ES] processed 500/1339 rows\n",
      "  [ES] processed 1000/1339 rows\n",
      "  [ES] processed 1339/1339 rows\n",
      "[ES] Done.\n",
      "  - rows: 1339\n",
      "  - non_conflict_rows: 350\n",
      "  - conflict_rows: 989\n",
      "  - src_ambiguous: 854\n",
      "  - tgt_ambiguous: 521\n",
      "  - both_no_match: 0\n",
      "  - src_single: 484\n",
      "  - tgt_single: 818\n",
      "  - both_single: 350\n",
      "  - wrote: en_es_prefrel_with_lexemes.csv (non-conflicts), en_es_prefrel_with_lexemes_conflicts.csv (conflicts)\n",
      "\n",
      "===== IT =====\n",
      "[INFO] Prefrel file: .\\en_it_prefrel_union.csv\n",
      "[INFO] Duo path    : .\\duo.csv\n",
      "[DUO] Building lemma map from duo.csv for combos [('en', 'it'), ('it', 'en')]\n",
      "  [DUO] Chunk 1 done: total_rows=200,000, kept=20,480, distinct_lemmas=1,279\n",
      "  [DUO] Chunk 2 done: total_rows=400,000, kept=33,728, distinct_lemmas=1,377\n",
      "  [DUO] Chunk 3 done: total_rows=600,000, kept=66,048, distinct_lemmas=1,758\n",
      "  [DUO] Chunk 4 done: total_rows=800,000, kept=93,571, distinct_lemmas=1,988\n",
      "  [DUO] Chunk 5 done: total_rows=1,000,000, kept=117,887, distinct_lemmas=2,060\n",
      "  [DUO] Chunk 6 done: total_rows=1,200,000, kept=130,396, distinct_lemmas=2,061\n",
      "  [DUO] Chunk 7 done: total_rows=1,400,000, kept=166,733, distinct_lemmas=2,159\n",
      "  [DUO] Chunk 8 done: total_rows=1,600,000, kept=195,058, distinct_lemmas=2,211\n",
      "  [DUO] Chunk 9 done: total_rows=1,800,000, kept=217,085, distinct_lemmas=2,215\n",
      "  [DUO] Chunk 10 done: total_rows=2,000,000, kept=242,320, distinct_lemmas=2,245\n",
      "  [DUO] Chunk 11 done: total_rows=2,200,000, kept=278,920, distinct_lemmas=2,298\n",
      "  [DUO] Chunk 12 done: total_rows=2,400,000, kept=309,096, distinct_lemmas=2,348\n",
      "  [DUO] Chunk 13 done: total_rows=2,600,000, kept=330,612, distinct_lemmas=2,358\n",
      "  [DUO] Chunk 14 done: total_rows=2,800,000, kept=354,146, distinct_lemmas=2,361\n",
      "  [DUO] Chunk 15 done: total_rows=3,000,000, kept=386,058, distinct_lemmas=2,393\n",
      "  [DUO] Chunk 16 done: total_rows=3,200,000, kept=412,570, distinct_lemmas=2,421\n",
      "  [DUO] Chunk 17 done: total_rows=3,400,000, kept=433,994, distinct_lemmas=2,447\n",
      "  [DUO] Chunk 18 done: total_rows=3,600,000, kept=451,726, distinct_lemmas=2,450\n",
      "  [DUO] Chunk 19 done: total_rows=3,800,000, kept=487,290, distinct_lemmas=2,453\n",
      "  [DUO] Chunk 20 done: total_rows=4,000,000, kept=516,047, distinct_lemmas=2,460\n",
      "  [DUO] Chunk 21 done: total_rows=4,200,000, kept=538,529, distinct_lemmas=2,465\n",
      "  [DUO] Chunk 22 done: total_rows=4,400,000, kept=553,294, distinct_lemmas=2,465\n",
      "  [DUO] Chunk 23 done: total_rows=4,600,000, kept=588,889, distinct_lemmas=2,470\n",
      "  [DUO] Chunk 24 done: total_rows=4,800,000, kept=618,708, distinct_lemmas=2,473\n",
      "  [DUO] Chunk 25 done: total_rows=5,000,000, kept=643,744, distinct_lemmas=2,478\n",
      "  [DUO] Chunk 26 done: total_rows=5,200,000, kept=662,395, distinct_lemmas=2,482\n",
      "  [DUO] Chunk 27 done: total_rows=5,400,000, kept=684,994, distinct_lemmas=2,491\n",
      "  [DUO] Chunk 28 done: total_rows=5,600,000, kept=719,467, distinct_lemmas=2,546\n",
      "  [DUO] Chunk 29 done: total_rows=5,800,000, kept=744,778, distinct_lemmas=2,547\n",
      "  [DUO] Chunk 30 done: total_rows=6,000,000, kept=763,693, distinct_lemmas=2,549\n",
      "  [DUO] Chunk 31 done: total_rows=6,200,000, kept=780,453, distinct_lemmas=2,549\n",
      "  [DUO] Chunk 32 done: total_rows=6,400,000, kept=818,120, distinct_lemmas=2,555\n",
      "  [DUO] Chunk 33 done: total_rows=6,600,000, kept=843,530, distinct_lemmas=2,555\n",
      "  [DUO] Chunk 34 done: total_rows=6,800,000, kept=866,173, distinct_lemmas=2,564\n",
      "  [DUO] Chunk 35 done: total_rows=7,000,000, kept=888,403, distinct_lemmas=2,566\n",
      "  [DUO] Chunk 36 done: total_rows=7,200,000, kept=923,098, distinct_lemmas=2,571\n",
      "  [DUO] Chunk 37 done: total_rows=7,400,000, kept=949,417, distinct_lemmas=2,574\n",
      "  [DUO] Chunk 38 done: total_rows=7,600,000, kept=967,062, distinct_lemmas=2,576\n",
      "  [DUO] Chunk 39 done: total_rows=7,800,000, kept=1,000,156, distinct_lemmas=2,638\n",
      "  [DUO] Chunk 40 done: total_rows=8,000,000, kept=1,031,029, distinct_lemmas=2,652\n",
      "  [DUO] Chunk 41 done: total_rows=8,200,000, kept=1,055,111, distinct_lemmas=2,655\n",
      "  [DUO] Chunk 42 done: total_rows=8,400,000, kept=1,073,025, distinct_lemmas=2,659\n",
      "  [DUO] Chunk 43 done: total_rows=8,600,000, kept=1,104,306, distinct_lemmas=2,692\n",
      "  [DUO] Chunk 44 done: total_rows=8,800,000, kept=1,132,637, distinct_lemmas=2,692\n",
      "  [DUO] Chunk 45 done: total_rows=9,000,000, kept=1,157,661, distinct_lemmas=2,692\n",
      "  [DUO] Chunk 46 done: total_rows=9,200,000, kept=1,171,645, distinct_lemmas=2,732\n",
      "  [DUO] Chunk 47 done: total_rows=9,400,000, kept=1,199,812, distinct_lemmas=2,745\n",
      "  [DUO] Chunk 48 done: total_rows=9,527,895, kept=1,218,087, distinct_lemmas=2,745\n",
      "[DUO] Finished. Total kept rows=1,218,087, distinct lemmas=2,745\n",
      "[IT] Enriching 962 rows ...\n",
      "  [IT] processed 500/962 rows\n",
      "  [IT] processed 962/962 rows\n",
      "[IT] Done.\n",
      "  - rows: 962\n",
      "  - non_conflict_rows: 419\n",
      "  - conflict_rows: 543\n",
      "  - src_ambiguous: 390\n",
      "  - tgt_ambiguous: 362\n",
      "  - both_no_match: 0\n",
      "  - src_single: 569\n",
      "  - tgt_single: 600\n",
      "  - both_single: 417\n",
      "  - wrote: en_it_prefrel_with_lexemes.csv (non-conflicts), en_it_prefrel_with_lexemes_conflicts.csv (conflicts)\n",
      "\n",
      "===== PT =====\n",
      "[INFO] Prefrel file: .\\en_pt_prefrel_union.csv\n",
      "[INFO] Duo path    : .\\duo.csv\n",
      "[DUO] Building lemma map from duo.csv for combos [('en', 'pt'), ('pt', 'en')]\n",
      "  [DUO] Chunk 1 done: total_rows=200,000, kept=27,550, distinct_lemmas=1,320\n",
      "  [DUO] Chunk 2 done: total_rows=400,000, kept=55,264, distinct_lemmas=1,666\n",
      "  [DUO] Chunk 3 done: total_rows=600,000, kept=77,469, distinct_lemmas=1,840\n",
      "  [DUO] Chunk 4 done: total_rows=800,000, kept=104,984, distinct_lemmas=2,013\n",
      "  [DUO] Chunk 5 done: total_rows=1,000,000, kept=130,973, distinct_lemmas=2,080\n",
      "  [DUO] Chunk 6 done: total_rows=1,200,000, kept=154,603, distinct_lemmas=2,182\n",
      "  [DUO] Chunk 7 done: total_rows=1,400,000, kept=179,268, distinct_lemmas=2,223\n",
      "  [DUO] Chunk 8 done: total_rows=1,600,000, kept=206,665, distinct_lemmas=2,299\n",
      "  [DUO] Chunk 9 done: total_rows=1,800,000, kept=237,506, distinct_lemmas=2,356\n",
      "  [DUO] Chunk 10 done: total_rows=2,000,000, kept=260,825, distinct_lemmas=2,374\n",
      "  [DUO] Chunk 11 done: total_rows=2,200,000, kept=288,911, distinct_lemmas=2,417\n",
      "  [DUO] Chunk 12 done: total_rows=2,400,000, kept=314,337, distinct_lemmas=2,439\n",
      "  [DUO] Chunk 13 done: total_rows=2,600,000, kept=345,085, distinct_lemmas=2,508\n",
      "  [DUO] Chunk 14 done: total_rows=2,800,000, kept=362,806, distinct_lemmas=2,519\n",
      "  [DUO] Chunk 15 done: total_rows=3,000,000, kept=388,155, distinct_lemmas=2,573\n",
      "  [DUO] Chunk 16 done: total_rows=3,200,000, kept=417,787, distinct_lemmas=2,583\n",
      "  [DUO] Chunk 17 done: total_rows=3,400,000, kept=450,038, distinct_lemmas=2,627\n",
      "  [DUO] Chunk 18 done: total_rows=3,600,000, kept=472,076, distinct_lemmas=2,650\n",
      "  [DUO] Chunk 19 done: total_rows=3,800,000, kept=499,671, distinct_lemmas=2,654\n",
      "  [DUO] Chunk 20 done: total_rows=4,000,000, kept=527,076, distinct_lemmas=2,698\n",
      "  [DUO] Chunk 21 done: total_rows=4,200,000, kept=559,180, distinct_lemmas=2,724\n",
      "  [DUO] Chunk 22 done: total_rows=4,400,000, kept=587,615, distinct_lemmas=2,741\n",
      "  [DUO] Chunk 23 done: total_rows=4,600,000, kept=610,155, distinct_lemmas=2,749\n",
      "  [DUO] Chunk 24 done: total_rows=4,800,000, kept=638,417, distinct_lemmas=2,783\n",
      "  [DUO] Chunk 25 done: total_rows=5,000,000, kept=664,982, distinct_lemmas=2,808\n",
      "  [DUO] Chunk 26 done: total_rows=5,200,000, kept=696,329, distinct_lemmas=2,817\n",
      "  [DUO] Chunk 27 done: total_rows=5,400,000, kept=713,659, distinct_lemmas=2,836\n",
      "  [DUO] Chunk 28 done: total_rows=5,600,000, kept=743,877, distinct_lemmas=2,853\n",
      "  [DUO] Chunk 29 done: total_rows=5,800,000, kept=772,283, distinct_lemmas=2,864\n",
      "  [DUO] Chunk 30 done: total_rows=6,000,000, kept=800,649, distinct_lemmas=2,877\n",
      "  [DUO] Chunk 31 done: total_rows=6,200,000, kept=825,550, distinct_lemmas=2,892\n",
      "  [DUO] Chunk 32 done: total_rows=6,400,000, kept=850,217, distinct_lemmas=2,901\n",
      "  [DUO] Chunk 33 done: total_rows=6,600,000, kept=877,084, distinct_lemmas=2,909\n",
      "  [DUO] Chunk 34 done: total_rows=6,800,000, kept=904,981, distinct_lemmas=2,911\n",
      "  [DUO] Chunk 35 done: total_rows=7,000,000, kept=926,595, distinct_lemmas=2,925\n",
      "  [DUO] Chunk 36 done: total_rows=7,200,000, kept=953,112, distinct_lemmas=2,925\n",
      "  [DUO] Chunk 37 done: total_rows=7,400,000, kept=980,828, distinct_lemmas=2,935\n",
      "  [DUO] Chunk 38 done: total_rows=7,600,000, kept=1,012,681, distinct_lemmas=2,935\n",
      "  [DUO] Chunk 39 done: total_rows=7,800,000, kept=1,032,378, distinct_lemmas=2,937\n",
      "  [DUO] Chunk 40 done: total_rows=8,000,000, kept=1,060,187, distinct_lemmas=2,941\n",
      "  [DUO] Chunk 41 done: total_rows=8,200,000, kept=1,087,977, distinct_lemmas=2,944\n",
      "  [DUO] Chunk 42 done: total_rows=8,400,000, kept=1,115,214, distinct_lemmas=2,958\n",
      "  [DUO] Chunk 43 done: total_rows=8,600,000, kept=1,135,454, distinct_lemmas=2,958\n",
      "  [DUO] Chunk 44 done: total_rows=8,800,000, kept=1,161,626, distinct_lemmas=2,958\n",
      "  [DUO] Chunk 45 done: total_rows=9,000,000, kept=1,187,064, distinct_lemmas=2,959\n",
      "  [DUO] Chunk 46 done: total_rows=9,200,000, kept=1,218,670, distinct_lemmas=2,963\n",
      "  [DUO] Chunk 47 done: total_rows=9,400,000, kept=1,238,582, distinct_lemmas=2,979\n",
      "  [DUO] Chunk 48 done: total_rows=9,527,895, kept=1,260,940, distinct_lemmas=2,979\n",
      "[DUO] Finished. Total kept rows=1,260,940, distinct lemmas=2,979\n",
      "[PT] Enriching 1150 rows ...\n",
      "  [PT] processed 500/1150 rows\n",
      "  [PT] processed 1000/1150 rows\n",
      "  [PT] processed 1150/1150 rows\n",
      "[PT] Done.\n",
      "  - rows: 1150\n",
      "  - non_conflict_rows: 300\n",
      "  - conflict_rows: 850\n",
      "  - src_ambiguous: 754\n",
      "  - tgt_ambiguous: 370\n",
      "  - both_no_match: 0\n",
      "  - src_single: 391\n",
      "  - tgt_single: 780\n",
      "  - both_single: 297\n",
      "  - wrote: en_pt_prefrel_with_lexemes.csv (non-conflicts), en_pt_prefrel_with_lexemes_conflicts.csv (conflicts)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Set, Tuple, List\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "BASE = \".\"  \n",
    "DUO_PATH = os.path.join(BASE, \"duo.csv\")  \n",
    "PREFREL_FILES = {\n",
    "    \"es\": os.path.join(BASE, \"en_es_prefrel_union.csv\"),\n",
    "    \"it\": os.path.join(BASE, \"en_it_prefrel_union.csv\"),\n",
    "    \"pt\": os.path.join(BASE, \"en_pt_prefrel_union.csv\"),\n",
    "}\n",
    "ALLOWED_COMBOS = {\n",
    "    \"es\": {(\"es\",\"en\"), (\"en\",\"es\")},\n",
    "    \"it\": {(\"it\",\"en\"), (\"en\",\"it\")},\n",
    "    \"pt\": {(\"pt\",\"en\"), (\"en\",\"pt\")},\n",
    "}\n",
    "\n",
    "KEY_COLS = [\"src_lemma\", \"tgt_lemma\"]\n",
    "DUO_COLS_NEEDED = [\"lemma\", \"lexeme_id\", \"lexeme_string\", \"learning_language\", \"ui_language\"]\n",
    "\n",
    "\n",
    "ENRICH_PROGRESS_EVERY = 500\n",
    "DUO_CHUNKSIZE = 200_000  \n",
    "\n",
    "\n",
    "def build_lemma_map_from_duo(duo_path: str, combos: Set[Tuple[str,str]]) -> Dict[str, Set[Tuple[str,str]]]:\n",
    "    \n",
    "    lemma_map: Dict[str, Set[Tuple[str,str]]] = defaultdict(set)\n",
    "\n",
    "    if not os.path.exists(duo_path):\n",
    "        raise FileNotFoundError(f\"duo.csv not found at: {duo_path}\")\n",
    "\n",
    "    total_rows = 0\n",
    "    kept_rows = 0\n",
    "    distinct_lemmas = 0\n",
    "    chunk_idx = 0\n",
    "\n",
    "    print(f\"[DUO] Building lemma map from {os.path.basename(duo_path)} for combos {sorted(combos)}\")\n",
    "    for chunk in pd.read_csv(duo_path, usecols=DUO_COLS_NEEDED, chunksize=DUO_CHUNKSIZE):\n",
    "        chunk_idx += 1\n",
    "        total_rows += len(chunk)\n",
    "\n",
    "        \n",
    "        mask = chunk.apply(lambda r: (str(r[\"learning_language\"]), str(r[\"ui_language\"])) in combos, axis=1)\n",
    "        sub = chunk.loc[mask, [\"lemma\", \"lexeme_id\", \"lexeme_string\"]]\n",
    "\n",
    "        kept_rows += len(sub)\n",
    "\n",
    "        \n",
    "        for lemma, lid, lstr in sub.itertuples(index=False):\n",
    "            \n",
    "            if pd.isna(lemma) or pd.isna(lid) or pd.isna(lstr):\n",
    "                continue\n",
    "            lemma_map[str(lemma)].add((str(lid), str(lstr)))\n",
    "\n",
    "        distinct_lemmas = len(lemma_map)\n",
    "        print(f\"  [DUO] Chunk {chunk_idx} done: total_rows={total_rows:,}, kept={kept_rows:,}, distinct_lemmas={distinct_lemmas:,}\")\n",
    "\n",
    "    print(f\"[DUO] Finished. Total kept rows={kept_rows:,}, distinct lemmas={distinct_lemmas:,}\")\n",
    "    return lemma_map\n",
    "\n",
    "def enrich_prefrel_with_lexemes(\n",
    "    prefrel_df: pd.DataFrame,\n",
    "    lemma_map: Dict[str, Set[Tuple[str,str]]],\n",
    "    lang_tag: str,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, dict]:\n",
    "    \n",
    "\n",
    "    rows_nonconf: List[dict] = []\n",
    "    rows_conf: List[dict] = []\n",
    "\n",
    "    \n",
    "    n_rows = len(prefrel_df)\n",
    "    src_ambig = tgt_ambig = 0\n",
    "    both_no_match = 0\n",
    "    src_single = tgt_single = 0\n",
    "    both_single = 0\n",
    "\n",
    "    \n",
    "    print(f\"[{lang_tag.upper()}] Enriching {n_rows} rows ...\")\n",
    "    for i, row in enumerate(prefrel_df.itertuples(index=False), 1):\n",
    "        src = str(getattr(row, \"src_lemma\"))\n",
    "        tgt = str(getattr(row, \"tgt_lemma\"))\n",
    "\n",
    "        \n",
    "        src_set = lemma_map.get(src, set())\n",
    "        tgt_set = lemma_map.get(tgt, set())\n",
    "\n",
    "        src_list = sorted(src_set)  \n",
    "        tgt_list = sorted(tgt_set)\n",
    "\n",
    "        \n",
    "        src_is_ambig = len(src_list) > 1\n",
    "        tgt_is_ambig = len(tgt_list) > 1\n",
    "        src_is_single = len(src_list) == 1\n",
    "        tgt_is_single = len(tgt_list) == 1\n",
    "        no_match_both = (len(src_list) == 0 and len(tgt_list) == 0)\n",
    "\n",
    "        if src_is_ambig: src_ambig += 1\n",
    "        if tgt_is_ambig: tgt_ambig += 1\n",
    "        if no_match_both: both_no_match += 1\n",
    "        if src_is_single: src_single += 1\n",
    "        if tgt_is_single: tgt_single += 1\n",
    "        if src_is_single and tgt_is_single: both_single += 1\n",
    "\n",
    "        \n",
    "        base = dict(zip(prefrel_df.columns, getattr(row, \"_fields\") and row))\n",
    "\n",
    "        \n",
    "        def unpack_single(lst):\n",
    "            if len(lst) == 1:\n",
    "                lid, lstr = lst[0]\n",
    "                return lid, lstr\n",
    "            return \"\", \"\"\n",
    "\n",
    "        src_lid, src_lstr = unpack_single(src_list)\n",
    "        tgt_lid, tgt_lstr = unpack_single(tgt_list)\n",
    "\n",
    "        base[\"src_lexeme_id\"] = src_lid\n",
    "        base[\"src_lexeme_string\"] = src_lstr\n",
    "        base[\"tgt_lexeme_id\"] = tgt_lid\n",
    "        base[\"tgt_lexeme_string\"] = tgt_lstr\n",
    "\n",
    "        \n",
    "        is_conflict = src_is_ambig or tgt_is_ambig or no_match_both\n",
    "\n",
    "        if is_conflict:\n",
    "            \n",
    "            base[\"src_lexeme_candidates\"] = \"; \".join([f\"{lid}|{lstr}\" for lid, lstr in src_list]) if src_list else \"\"\n",
    "            base[\"tgt_lexeme_candidates\"] = \"; \".join([f\"{lid}|{lstr}\" for lid, lstr in tgt_list]) if tgt_list else \"\"\n",
    "            rows_conf.append(base)\n",
    "        else:\n",
    "            rows_nonconf.append(base)\n",
    "\n",
    "        \n",
    "        if i % ENRICH_PROGRESS_EVERY == 0 or i == n_rows:\n",
    "            print(f\"  [{lang_tag.upper()}] processed {i}/{n_rows} rows\")\n",
    "\n",
    "    nonconf_df = pd.DataFrame(rows_nonconf) if rows_nonconf else pd.DataFrame(columns=prefrel_df.columns.tolist() + [\"src_lexeme_id\",\"src_lexeme_string\",\"tgt_lexeme_id\",\"tgt_lexeme_string\"])\n",
    "    conf_df = pd.DataFrame(rows_conf) if rows_conf else pd.DataFrame(columns=prefrel_df.columns.tolist() + [\"src_lexeme_id\",\"src_lexeme_string\",\"tgt_lexeme_id\",\"tgt_lexeme_string\",\"src_lexeme_candidates\",\"tgt_lexeme_candidates\"])\n",
    "\n",
    "    stats = {\n",
    "        \"rows\": n_rows,\n",
    "        \"non_conflict_rows\": len(nonconf_df),\n",
    "        \"conflict_rows\": len(conf_df),\n",
    "        \"src_ambiguous\": src_ambig,\n",
    "        \"tgt_ambiguous\": tgt_ambig,\n",
    "        \"both_no_match\": both_no_match,\n",
    "        \"src_single\": src_single,\n",
    "        \"tgt_single\": tgt_single,\n",
    "        \"both_single\": both_single,\n",
    "    }\n",
    "    return nonconf_df, conf_df, stats\n",
    "\n",
    "def run_for_language(lang: str):\n",
    "    prefrel_path = PREFREL_FILES[lang]\n",
    "    combos = ALLOWED_COMBOS[lang]\n",
    "\n",
    "    if not os.path.exists(prefrel_path):\n",
    "        print(f\"[{lang.upper()}] SKIP (missing prefrel file): {prefrel_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n===== {lang.upper()} =====\")\n",
    "    print(f\"[INFO] Prefrel file: {prefrel_path}\")\n",
    "    print(f\"[INFO] Duo path    : {DUO_PATH}\")\n",
    "\n",
    "    \n",
    "    lemma_map = build_lemma_map_from_duo(DUO_PATH, combos)\n",
    "\n",
    "    \n",
    "    prefrel_df = pd.read_csv(prefrel_path)\n",
    "    for c in KEY_COLS:\n",
    "        if c not in prefrel_df.columns:\n",
    "            raise ValueError(f\"{os.path.basename(prefrel_path)} missing required column: {c}\")\n",
    "\n",
    "    \n",
    "    nonconf_df, conf_df, stats = enrich_prefrel_with_lexemes(prefrel_df, lemma_map, lang)\n",
    "\n",
    "    \n",
    "    out_main = os.path.join(BASE, f\"en_{lang}_prefrel_with_lexemes.csv\")\n",
    "    out_conf = os.path.join(BASE, f\"en_{lang}_prefrel_with_lexemes_conflicts.csv\")\n",
    "    nonconf_df.to_csv(out_main, index=False)\n",
    "    conf_df.to_csv(out_conf, index=False)\n",
    "\n",
    "    \n",
    "    print(f\"[{lang.upper()}] Done.\")\n",
    "    for k, v in stats.items():\n",
    "        print(f\"  - {k}: {v}\")\n",
    "    print(f\"  - wrote: {os.path.basename(out_main)} (non-conflicts), {os.path.basename(out_conf)} (conflicts)\")\n",
    "\n",
    "\n",
    "for lang in [\"es\", \"it\", \"pt\"]:\n",
    "    run_for_language(lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c69f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ES ===\n",
      "  [OK] en_es_prefrel_with_lexemes.csv | dropped: none | lexeme_order: ['src_lexeme_string', 'tgt_lexeme_string', 'src_lexeme_id', 'tgt_lexeme_id'] | moved_to_end: ['score', 'quality'] | cols: 10→10\n",
      "  [OK] en_es_prefrel_with_lexemes_conflicts.csv | dropped: none | lexeme_order: ['src_lexeme_string', 'tgt_lexeme_string', 'src_lexeme_id', 'tgt_lexeme_id'] | moved_to_end: ['score', 'quality'] | cols: 12→12\n",
      "\n",
      "=== IT ===\n",
      "  [OK] en_it_prefrel_with_lexemes.csv | dropped: none | lexeme_order: ['src_lexeme_string', 'tgt_lexeme_string', 'src_lexeme_id', 'tgt_lexeme_id'] | moved_to_end: ['score', 'quality'] | cols: 10→10\n",
      "  [OK] en_it_prefrel_with_lexemes_conflicts.csv | dropped: none | lexeme_order: ['src_lexeme_string', 'tgt_lexeme_string', 'src_lexeme_id', 'tgt_lexeme_id'] | moved_to_end: ['score', 'quality'] | cols: 12→12\n",
      "\n",
      "=== PT ===\n",
      "  [OK] en_pt_prefrel_with_lexemes.csv | dropped: none | lexeme_order: ['src_lexeme_string', 'tgt_lexeme_string', 'src_lexeme_id', 'tgt_lexeme_id'] | moved_to_end: ['score', 'quality'] | cols: 10→10\n",
      "  [OK] en_pt_prefrel_with_lexemes_conflicts.csv | dropped: none | lexeme_order: ['src_lexeme_string', 'tgt_lexeme_string', 'src_lexeme_id', 'tgt_lexeme_id'] | moved_to_end: ['score', 'quality'] | cols: 12→12\n",
      "\n",
      "✅ Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "BASE = \".\"                       \n",
    "LANGS = [\"es\", \"it\", \"pt\"]\n",
    "DROP_COLS = [\"semantic_score\", \"from_wordnet\", \"round_trip\", \"max_sem_sim\"]\n",
    "OVERWRITE = True                 \n",
    "\n",
    "\n",
    "TAIL_COLS = [\"score\", \"quality\"]\n",
    "\n",
    "\n",
    "LEXEME_ORDER = [\n",
    "    \"src_lexeme_string\",\n",
    "    \"tgt_lexeme_string\",\n",
    "    \"src_lexeme_id\",\n",
    "    \"tgt_lexeme_id\",\n",
    "]\n",
    "\n",
    "def reorder_columns(df: pd.DataFrame) -> tuple[pd.DataFrame, list[str], list[str], list[str]]:\n",
    "    \n",
    "\n",
    "\n",
    "    to_drop = [c for c in DROP_COLS if c in df.columns]\n",
    "    if to_drop:\n",
    "        df = df.drop(columns=to_drop)\n",
    "\n",
    "    \n",
    "    lexeme_present = [c for c in LEXEME_ORDER if c in df.columns]\n",
    "    tails_present  = [c for c in TAIL_COLS if c in df.columns]\n",
    "\n",
    "    \n",
    "    core_cols = [c for c in df.columns if c not in lexeme_present and c not in tails_present]\n",
    "\n",
    "    \n",
    "    new_order = core_cols + lexeme_present + tails_present\n",
    "    df = df[new_order]\n",
    "    return df, to_drop, lexeme_present, tails_present\n",
    "\n",
    "def tidy_file(path: str) -> None:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"  [SKIP] {os.path.basename(path)} (not found)\")\n",
    "        return\n",
    "    df = pd.read_csv(path)\n",
    "    before_cols = len(df.columns)\n",
    "\n",
    "    df, dropped, lexeme_order, tails = reorder_columns(df)\n",
    "\n",
    "    out_path = path if OVERWRITE else path.replace(\".csv\", \"_tidy.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(\n",
    "        f\"  [OK] {os.path.basename(out_path)} | \"\n",
    "        f\"dropped: {dropped or 'none'} | \"\n",
    "        f\"lexeme_order: {lexeme_order or 'none'} | \"\n",
    "        f\"moved_to_end: {tails or 'none'} | \"\n",
    "        f\"cols: {before_cols}→{len(df.columns)}\"\n",
    "    )\n",
    "\n",
    "def run():\n",
    "    for xx in LANGS:\n",
    "        print(f\"\\n=== {xx.upper()} ===\")\n",
    "        for suffix in [\"with_lexemes.csv\", \"with_lexemes_conflicts.csv\"]:\n",
    "            tidy_file(os.path.join(BASE, f\"en_{xx}_prefrel_{suffix}\"))\n",
    "    print(\"\\n✅ Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89487e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading en_pt_prefrel_with_lexemes_conflicts.csv ...\n",
      "[INFO] Counting candidates...\n",
      "[OK] Added count columns and saved → en_pt_prefrel_with_lexemes_conflicts.csv\n",
      "    Total rows processed: 850\n",
      "    Columns now: ['src_lemma', 'tgt_lemma', 'src_pos', 'tgt_pos', 'src_lexeme_candidates', 'tgt_lexeme_candidates', 'src_lexeme_string', 'tgt_lexeme_string', 'src_lexeme_id', 'tgt_lexeme_id', 'score', 'quality', 'src_lexeme_candidates_count', 'tgt_lexeme_candidates_count']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "BASE = \".\"  \n",
    "FILE = os.path.join(BASE, \"en_pt_prefrel_with_lexemes_conflicts.csv\")\n",
    "OVERWRITE = True  \n",
    "\n",
    "SRC_COL = \"src_lexeme_candidates\"\n",
    "TGT_COL = \"tgt_lexeme_candidates\"\n",
    "\n",
    "def count_candidates(entry: str) -> int:\n",
    "    \"\"\"Count how many 'lexeme_id|lexeme_string' pairs exist in a candidate cell.\"\"\"\n",
    "    if pd.isna(entry) or not str(entry).strip():\n",
    "        return 0\n",
    "    return len(str(entry).split(\";\"))\n",
    "\n",
    "def add_candidate_counts(path: str) -> None:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[ERROR] File not found: {path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"[INFO] Loading {os.path.basename(path)} ...\")\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    if SRC_COL not in df.columns or TGT_COL not in df.columns:\n",
    "        print(f\"[WARN] Missing candidate columns in {os.path.basename(path)}.\")\n",
    "        return\n",
    "\n",
    "    print(\"[INFO] Counting candidates...\")\n",
    "    df[\"src_lexeme_candidates_count\"] = df[SRC_COL].apply(count_candidates)\n",
    "    df[\"tgt_lexeme_candidates_count\"] = df[TGT_COL].apply(count_candidates)\n",
    "\n",
    "    out_path = path if OVERWRITE else path.replace(\".csv\", \"_counted.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"[OK] Added count columns and saved → {os.path.basename(out_path)}\")\n",
    "    print(f\"    Total rows processed: {len(df)}\")\n",
    "    print(f\"    Columns now: {list(df.columns)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    add_candidate_counts(FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e01fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ES conflict resolver ===\n",
      "[LOAD] .\\en_es_prefrel_with_lexemes_conflicts.csv\n",
      "[WORK] Resolving 989 rows (every 500) ...\n",
      "  processed 500/989\n",
      "  processed 989/989\n",
      "[DONE] ES: resolved=824, unresolved=165\n",
      "       wrote: en_es_prefrel_with_lexemes_resolved.csv, en_es_prefrel_with_lexemes_unresolved.csv\n",
      "\n",
      "=== IT conflict resolver ===\n",
      "[LOAD] .\\en_it_prefrel_with_lexemes_conflicts.csv\n",
      "[WORK] Resolving 543 rows (every 500) ...\n",
      "  processed 500/543\n",
      "  processed 543/543\n",
      "[DONE] IT: resolved=435, unresolved=108\n",
      "       wrote: en_it_prefrel_with_lexemes_resolved.csv, en_it_prefrel_with_lexemes_unresolved.csv\n",
      "\n",
      "=== PT conflict resolver ===\n",
      "[LOAD] .\\en_pt_prefrel_with_lexemes_conflicts.csv\n",
      "[WORK] Resolving 850 rows (every 500) ...\n",
      "  processed 500/850\n",
      "  processed 850/850\n",
      "[DONE] PT: resolved=733, unresolved=117\n",
      "       wrote: en_pt_prefrel_with_lexemes_resolved.csv, en_pt_prefrel_with_lexemes_unresolved.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "BASE = \".\"  \n",
    "LANGS = [\"es\", \"it\", \"pt\"]\n",
    "CONFLICT_TPL = \"en_{xx}_prefrel_with_lexemes_conflicts.csv\"\n",
    "OUT_RESOLVED_TPL = \"en_{xx}_prefrel_with_lexemes_resolved.csv\"\n",
    "OUT_UNRESOLVED_TPL = \"en_{xx}_prefrel_with_lexemes_unresolved.csv\"\n",
    "PROGRESS_EVERY = 500  \n",
    "\n",
    "\n",
    "\n",
    "def _norm_text(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = s.casefold()\n",
    "    return \"\".join(ch for ch in unicodedata.normalize(\"NFD\", s) if unicodedata.category(ch) != \"Mn\")\n",
    "\n",
    "def sane_list(cell: str) -> List[str]:\n",
    "    \"\"\"Split 'id|string; id|string' into individual candidate entries.\"\"\"\n",
    "    if cell is None or (isinstance(cell, float) and pd.isna(cell)):\n",
    "        return []\n",
    "    s = str(cell).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    \n",
    "    parts = [p.strip() for p in s.split(\";\") if p.strip()]\n",
    "    return parts\n",
    "\n",
    "def parse_candidate_pair(entry: str) -> Tuple[str, str]:\n",
    "    \"\"\"Parse a 'lexeme_id|lexeme_string' entry (bar may be missing).\"\"\"\n",
    "    if \"|\" in entry:\n",
    "        lid, lstr = entry.split(\"|\", 1)\n",
    "        return lid.strip(), lstr.strip()\n",
    "    \n",
    "    return \"\", entry.strip()\n",
    "\n",
    "\n",
    "_POS_CANON = {\n",
    "    \"noun\": {\"n\", \"n.\", \"noun\", \"s\", \"s.\", \"sost\", \"sost.\", \"sostantivo\", \"sust\", \"sust.\", \"sustantivo\", \"substantivo\", \"subst\", \"subst.\"},\n",
    "    \"verb\": {\"v\", \"v.\", \"verb\", \"vb\", \"vtr\", \"vi\", \"vt\", \"v intr\", \"v tr\", \"verbo\", \"verbo.\", \"v. intr.\", \"v. tr.\"},\n",
    "    \"adj\":  {\"adj\", \"adj.\", \"adjective\", \"aggettivo\", \"agg\", \"agg.\", \"adjetivo\", \"adjétivo\"},\n",
    "    \"adv\":  {\"adv\", \"adv.\", \"adverb\", \"avv\", \"avv.\", \"adverbio\", \"advérbio\"},\n",
    "    \"pron\": {\"pron\", \"pron.\", \"pronoun\", \"pronome\", \"pronombre\"},\n",
    "    \"det\":  {\"det\", \"det.\", \"determiner\", \"determinante\", \"art\", \"art.\", \"articolo\", \"artículo\", \"article\"},\n",
    "    \"prep\": {\"prep\", \"prep.\", \"preposition\", \"preposizione\", \"preposición\", \"preposição\"},\n",
    "    \"conj\": {\"conj\", \"conj.\", \"conjunction\", \"congiunzione\", \"conjunción\", \"conjunção\"},\n",
    "    \"interj\": {\"interj\", \"interj.\", \"interjection\", \"interiezione\", \"interjección\", \"interjeição\"},\n",
    "    \"num\":  {\"num\", \"num.\", \"numero\", \"numeral\", \"numerale\"},\n",
    "    \"part\": {\"part\", \"part.\", \"particle\", \"particella\", \"partícula\"},\n",
    "}\n",
    "_POS_TOKEN2CANON = {tok: canon for canon, toks in _POS_CANON.items() for tok in toks}\n",
    "\n",
    "\n",
    "_POS_PATTERNS = [\n",
    "    r\"\\(([^)]+)\\)\",                 \n",
    "    r\"\\[([^\\]]+)\\]\",                \n",
    "    r\"—\\s*([^-;·|,]+)\",             \n",
    "    r\"-\\s*([^-;·|,]+)\",             \n",
    "    r\"[;:,]\\s*([A-Za-z\\. ]{1,20})$\",\n",
    "    r\"^\\s*([A-Za-z\\. ]{1,20})\\s*[:\\-–—]\\s\",  \n",
    "]\n",
    "\n",
    "def _tokenize_pos_zone(zone: str) -> List[str]:\n",
    "    z = _norm_text(zone)\n",
    "    \n",
    "    z = re.sub(r\"\\b(masc|fem|m|f|pl|sing|sg|plur)\\b\\.?\", \" \", z)\n",
    "    toks = re.split(r\"[ \\./;,\\|]+\", z)\n",
    "    return [t for t in toks if t]\n",
    "\n",
    "def normalize_user_pos(pos: str | None) -> str | None:\n",
    "    if not pos:\n",
    "        return None\n",
    "    p = _norm_text(pos)\n",
    "    for canon, toks in _POS_CANON.items():\n",
    "        if p in toks or p == canon:\n",
    "            return canon\n",
    "    \n",
    "    if p.startswith(\"v\"):\n",
    "        return \"verb\"\n",
    "    if p.startswith(\"adj\"):\n",
    "        return \"adj\"\n",
    "    if p.startswith(\"adv\"):\n",
    "        return \"adv\"\n",
    "    if p.startswith(\"n\"):\n",
    "        return \"noun\"\n",
    "    return p\n",
    "\n",
    "def extract_pos_from_lexeme_string(lexeme_string: str) -> str | None:\n",
    "    \n",
    "    if not lexeme_string:\n",
    "        return None\n",
    "    text = lexeme_string.strip()\n",
    "    zones: List[str] = []\n",
    "\n",
    "    \n",
    "    for pat in _POS_PATTERNS:\n",
    "        for m in re.finditer(pat, text):\n",
    "            zones.append(m.group(1))\n",
    "\n",
    "    \n",
    "    m = re.search(\n",
    "        r\"(adj\\.?|adv\\.?|v\\.?\\s*(?:tr|intr)?\\.?|n\\.?|sust\\.?|sost\\.?|verbo|aggettivo|adjetivo|adverbio|preposici[oó]n|preposizione)\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE,\n",
    "    )\n",
    "    if m:\n",
    "        zones.append(m.group(0))\n",
    "\n",
    "    \n",
    "    for z in zones:\n",
    "        for tok in _tokenize_pos_zone(z):\n",
    "            if tok in _POS_TOKEN2CANON:\n",
    "                return _POS_TOKEN2CANON[tok]\n",
    "\n",
    "    \n",
    "    for tok, canon in _POS_TOKEN2CANON.items():\n",
    "        if re.search(rf\"\\b{re.escape(tok)}\\b\", _norm_text(text)):\n",
    "            return canon\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def score_candidate(lemma: str,\n",
    "                    candidate: tuple[str, str],\n",
    "                    expected_pos: str | None) -> float:\n",
    "    \n",
    "\n",
    "    lid, lstr = candidate\n",
    "    score = 0.0\n",
    "\n",
    "    if _norm_text(lstr) == _norm_text(lemma):\n",
    "        score += 5.0\n",
    "\n",
    "    if expected_pos:\n",
    "        cand_pos = extract_pos_from_lexeme_string(lstr)\n",
    "        if cand_pos and normalize_user_pos(expected_pos) == cand_pos:\n",
    "            score += 2.0\n",
    "\n",
    "    score -= abs(len(lstr) - len(lemma)) * 0.01\n",
    "    return score\n",
    "\n",
    "def resolve_row_using_string_pos(row: pd.Series) -> tuple[bool, dict]:\n",
    "    \n",
    "\n",
    "\n",
    "    src_lemma = str(row[\"src_lemma\"])\n",
    "    tgt_lemma = str(row[\"tgt_lemma\"])\n",
    "    src_pos = normalize_user_pos(row[\"src_pos\"]) if \"src_pos\" in row and pd.notna(row[\"src_pos\"]) else None\n",
    "    tgt_pos = normalize_user_pos(row[\"tgt_pos\"]) if \"tgt_pos\" in row and pd.notna(row[\"tgt_pos\"]) else None\n",
    "\n",
    "    \n",
    "    src_cands = [parse_candidate_pair(e) for e in sane_list(row.get(\"src_lexeme_candidates\", \"\"))]\n",
    "    tgt_cands = [parse_candidate_pair(e) for e in sane_list(row.get(\"tgt_lexeme_candidates\", \"\"))]\n",
    "\n",
    "    \n",
    "    def choose(lemma, pos, cands):\n",
    "        if not cands:\n",
    "            return None, 0.0, []\n",
    "        scores = [(score_candidate(lemma, c, pos), c) for c in cands]\n",
    "        \n",
    "        scores.sort(key=lambda x: (-x[0], _norm_text(x[1][1]), x[1][0]))\n",
    "        best_score = scores[0][0]\n",
    "        best = [c for s, c in scores if s == best_score]\n",
    "        \n",
    "        return (best[0] if len(best) == 1 else None), best_score, scores\n",
    "\n",
    "    src_choice, src_score, src_scores = choose(src_lemma, src_pos, src_cands)\n",
    "    tgt_choice, tgt_score, tgt_scores = choose(tgt_lemma, tgt_pos, tgt_cands)\n",
    "\n",
    "    out = dict(row)\n",
    "\n",
    "    \n",
    "    if src_choice:\n",
    "        out[\"src_lexeme_id\"], out[\"src_lexeme_string\"] = src_choice\n",
    "    if tgt_choice:\n",
    "        out[\"tgt_lexeme_id\"], out[\"tgt_lexeme_string\"] = tgt_choice\n",
    "\n",
    "    \n",
    "    src_resolved = src_choice is not None\n",
    "    tgt_resolved = tgt_choice is not None\n",
    "    resolved = src_resolved and tgt_resolved\n",
    "\n",
    "    \n",
    "    out[\"src_choice_score\"] = src_score if src_scores else \"\"\n",
    "    out[\"tgt_choice_score\"] = tgt_score if tgt_scores else \"\"\n",
    "    out[\"src_pos_extracted_from_choice\"] = extract_pos_from_lexeme_string(src_choice[1]) if src_choice else \"\"\n",
    "    out[\"tgt_pos_extracted_from_choice\"] = extract_pos_from_lexeme_string(tgt_choice[1]) if tgt_choice else \"\"\n",
    "    out[\"src_top_ties\"] = len([1 for s, c in src_scores if s == src_score]) if src_scores else 0\n",
    "    out[\"tgt_top_ties\"] = len([1 for s, c in tgt_scores if s == tgt_score]) if tgt_scores else 0\n",
    "\n",
    "    return resolved, out\n",
    "\n",
    "\n",
    "def run_resolver_for_language(xx: str):\n",
    "    conf_path = os.path.join(BASE, CONFLICT_TPL.format(xx=xx))\n",
    "    if not os.path.exists(conf_path):\n",
    "        print(f\"[{xx.upper()}] Conflicts file not found: {conf_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n=== {xx.upper()} conflict resolver ===\")\n",
    "    print(f\"[LOAD] {conf_path}\")\n",
    "    df = pd.read_csv(conf_path)\n",
    "    n = len(df)\n",
    "    print(f\"[WORK] Resolving {n} rows (every {PROGRESS_EVERY}) ...\")\n",
    "\n",
    "    resolved_rows = []\n",
    "    unresolved_rows = []\n",
    "\n",
    "    for i, row in enumerate(df.itertuples(index=False), 1):\n",
    "        resolved, out = resolve_row_using_string_pos(pd.Series(row._asdict()))\n",
    "        (resolved_rows if resolved else unresolved_rows).append(out)\n",
    "        if i % PROGRESS_EVERY == 0 or i == n:\n",
    "            print(f\"  processed {i}/{n}\")\n",
    "\n",
    "    out_resolved = os.path.join(BASE, OUT_RESOLVED_TPL.format(xx=xx))\n",
    "    out_unresolved = os.path.join(BASE, OUT_UNRESOLVED_TPL.format(xx=xx))\n",
    "    pd.DataFrame(resolved_rows).to_csv(out_resolved, index=False)\n",
    "    pd.DataFrame(unresolved_rows).to_csv(out_unresolved, index=False)\n",
    "\n",
    "    print(f\"[DONE] {xx.upper()}: resolved={len(resolved_rows)}, unresolved={len(unresolved_rows)}\")\n",
    "    print(f\"       wrote: {os.path.basename(out_resolved)}, {os.path.basename(out_unresolved)}\")\n",
    "\n",
    "\n",
    "for xx in LANGS:\n",
    "    run_resolver_for_language(xx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d1ee2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ES diagnostics ===\n",
      "  [LOAD] unresolved: .\\en_es_prefrel_with_lexemes_unresolved.csv\n",
      "[ES] Analyzing 165 rows (progress every 500) ...\n",
      "  processed 165/165\n",
      "  [SAVE] unresolved analyzed → en_es_prefrel_unresolved_analyzed.csv  (165 rows)\n",
      "  [LOAD] resolved: .\\en_es_prefrel_with_lexemes_resolved.csv\n",
      "[ES] Analyzing 824 rows (progress every 500) ...\n",
      "  processed 500/824\n",
      "  processed 824/824\n",
      "  [SAVE] resolved analyzed → en_es_prefrel_resolved_analyzed.csv  (824 rows)\n",
      "  [SUMMARY] wrote en_es_analysis_summary.csv\n",
      "\n",
      "=== IT diagnostics ===\n",
      "  [LOAD] unresolved: .\\en_it_prefrel_with_lexemes_unresolved.csv\n",
      "[IT] Analyzing 108 rows (progress every 500) ...\n",
      "  processed 108/108\n",
      "  [SAVE] unresolved analyzed → en_it_prefrel_unresolved_analyzed.csv  (108 rows)\n",
      "  [LOAD] resolved: .\\en_it_prefrel_with_lexemes_resolved.csv\n",
      "[IT] Analyzing 435 rows (progress every 500) ...\n",
      "  processed 435/435\n",
      "  [SAVE] resolved analyzed → en_it_prefrel_resolved_analyzed.csv  (435 rows)\n",
      "  [SUMMARY] wrote en_it_analysis_summary.csv\n",
      "\n",
      "=== PT diagnostics ===\n",
      "  [LOAD] unresolved: .\\en_pt_prefrel_with_lexemes_unresolved.csv\n",
      "[PT] Analyzing 117 rows (progress every 500) ...\n",
      "  processed 117/117\n",
      "  [SAVE] unresolved analyzed → en_pt_prefrel_unresolved_analyzed.csv  (117 rows)\n",
      "  [LOAD] resolved: .\\en_pt_prefrel_with_lexemes_resolved.csv\n",
      "[PT] Analyzing 733 rows (progress every 500) ...\n",
      "  processed 500/733\n",
      "  processed 733/733\n",
      "  [SAVE] resolved analyzed → en_pt_prefrel_resolved_analyzed.csv  (733 rows)\n",
      "  [SUMMARY] wrote en_pt_analysis_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "BASE = \".\"         \n",
    "LANGS = [\"es\", \"it\", \"pt\"]\n",
    "PROGRESS_EVERY = 500\n",
    "\n",
    "#\n",
    "INPUTS = {\n",
    "    \"resolved\":   \"en_{xx}_prefrel_with_lexemes_resolved.csv\",\n",
    "    \"unresolved\": \"en_{xx}_prefrel_with_lexemes_unresolved.csv\",\n",
    "}\n",
    "OUTPUTS = {\n",
    "    \"resolved\":   \"en_{xx}_prefrel_resolved_analyzed.csv\",\n",
    "    \"unresolved\": \"en_{xx}_prefrel_unresolved_analyzed.csv\",\n",
    "}\n",
    "SUMMARY_TPL = \"en_{xx}_analysis_summary.csv\"\n",
    "\n",
    "\n",
    "def _norm_text(s):\n",
    "    \"\"\"Normalize text safely (handles NaN, None, floats).\"\"\"\n",
    "    try:\n",
    "        if s is None or (isinstance(s, float) and pd.isna(s)):\n",
    "            return \"\"\n",
    "    except Exception:\n",
    "        if s is None:\n",
    "            return \"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = str(s)\n",
    "        if s.lower() == \"nan\":\n",
    "            return \"\"\n",
    "    s = s.casefold()\n",
    "    return \"\".join(ch for ch in unicodedata.normalize(\"NFD\", s) if unicodedata.category(ch) != \"Mn\")\n",
    "\n",
    "def sane_list(cell: str) -> List[str]:\n",
    "    \"\"\"Split 'id|string; id|string' into entries.\"\"\"\n",
    "    if cell is None or (isinstance(cell, float) and pd.isna(cell)):\n",
    "        return []\n",
    "    s = str(cell).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    return [p.strip() for p in s.split(\";\") if p.strip()]\n",
    "\n",
    "def parse_candidate_pair(entry: str) -> Tuple[str, str]:\n",
    "    \"\"\"Parse 'lexeme_id|lexeme_string' (bar may be missing).\"\"\"\n",
    "    if \"|\" in entry:\n",
    "        lid, lstr = entry.split(\"|\", 1)\n",
    "        return lid.strip(), lstr.strip()\n",
    "    return \"\", entry.strip()\n",
    "\n",
    "\n",
    "_POS_CANON = {\n",
    "    \"noun\": {\"n\", \"n.\", \"noun\", \"s\", \"s.\", \"sost\", \"sost.\", \"sostantivo\", \"sust\", \"sust.\", \"sustantivo\", \"substantivo\", \"subst\", \"subst.\"},\n",
    "    \"verb\": {\"v\", \"v.\", \"verb\", \"vb\", \"vtr\", \"vi\", \"vt\", \"v intr\", \"v tr\", \"verbo\", \"verbo.\", \"v. intr.\", \"v. tr.\"},\n",
    "    \"adj\":  {\"adj\", \"adj.\", \"adjective\", \"aggettivo\", \"agg\", \"agg.\", \"adjetivo\", \"adjétivo\"},\n",
    "    \"adv\":  {\"adv\", \"adv.\", \"adverb\", \"avv\", \"avv.\", \"adverbio\", \"advérbio\"},\n",
    "    \"pron\": {\"pron\", \"pron.\", \"pronoun\", \"pronome\", \"pronombre\"},\n",
    "    \"det\":  {\"det\", \"det.\", \"determiner\", \"determinante\", \"art\", \"art.\", \"articolo\", \"artículo\", \"article\"},\n",
    "    \"prep\": {\"prep\", \"prep.\", \"preposition\", \"preposizione\", \"preposición\", \"preposição\"},\n",
    "    \"conj\": {\"conj\", \"conj.\", \"conjunction\", \"congiunzione\", \"conjunción\", \"conjunção\"},\n",
    "    \"interj\": {\"interj\", \"interj.\", \"interjection\", \"interiezione\", \"interjección\", \"interjeição\"},\n",
    "    \"num\":  {\"num\", \"num.\", \"numero\", \"numeral\", \"numerale\"},\n",
    "    \"part\": {\"part\", \"part.\", \"particle\", \"particella\", \"partícula\"},\n",
    "}\n",
    "_POS_TOKEN2CANON = {tok: canon for canon, toks in _POS_CANON.items() for tok in toks}\n",
    "\n",
    "_POS_PATTERNS = [\n",
    "    r\"\\(([^)]+)\\)\",                 \n",
    "    r\"\\[([^\\]]+)\\]\",                \n",
    "    r\"—\\s*([^-;·|,]+)\",             \n",
    "    r\"-\\s*([^-;·|,]+)\",             \n",
    "    r\"[;:,]\\s*([A-Za-z\\. ]{1,20})$\",\n",
    "    r\"^\\s*([A-Za-z\\. ]{1,20})\\s*[:\\-–—]\\s\",  \n",
    "]\n",
    "\n",
    "def _tokenize_pos_zone(zone: str) -> List[str]:\n",
    "    z = _norm_text(zone)\n",
    "    z = re.sub(r\"\\b(masc|fem|m|f|pl|sing|sg|plur)\\b\\.?\", \" \", z)\n",
    "    toks = re.split(r\"[ \\./;,\\|]+\", z)\n",
    "    return [t for t in toks if t]\n",
    "\n",
    "def normalize_user_pos(pos):\n",
    "    \"\"\"Return canonical coarse POS or None; robust to NaN/None.\"\"\"\n",
    "    try:\n",
    "        if pos is None or (isinstance(pos, float) and pd.isna(pos)):\n",
    "            return None\n",
    "    except Exception:\n",
    "        if pos is None:\n",
    "            return None\n",
    "    p = _norm_text(pos)\n",
    "    if not p:\n",
    "        return None\n",
    "    for canon, toks in _POS_CANON.items():\n",
    "        if p in toks or p == canon:\n",
    "            return canon\n",
    "    if p.startswith(\"v\"):   return \"verb\"\n",
    "    if p.startswith(\"adj\"): return \"adj\"\n",
    "    if p.startswith(\"adv\"): return \"adv\"\n",
    "    if p.startswith(\"n\"):   return \"noun\"\n",
    "    return p\n",
    "\n",
    "def extract_pos_from_lexeme_string(lexeme_string: str) -> str | None:\n",
    "    if not lexeme_string:\n",
    "        return None\n",
    "    text = lexeme_string.strip()\n",
    "    zones: List[str] = []\n",
    "    for pat in _POS_PATTERNS:\n",
    "        for m in re.finditer(pat, text):\n",
    "            zones.append(m.group(1))\n",
    "    m = re.search(\n",
    "        r\"(adj\\.?|adv\\.?|v\\.?\\s*(?:tr|intr)?\\.?|n\\.?|sust\\.?|sost\\.?|verbo|aggettivo|adjetivo|adverbio|preposici[oó]n|preposizione)\",\n",
    "        text, flags=re.IGNORECASE\n",
    "    )\n",
    "    if m:\n",
    "        zones.append(m.group(0))\n",
    "    for z in zones:\n",
    "        for tok in _tokenize_pos_zone(z):\n",
    "            if tok in _POS_TOKEN2CANON:\n",
    "                return _POS_TOKEN2CANON[tok]\n",
    "    for tok, canon in _POS_TOKEN2CANON.items():\n",
    "        if re.search(rf\"\\b{re.escape(tok)}\\b\", _norm_text(text)):\n",
    "            return canon\n",
    "    return None\n",
    "\n",
    "\n",
    "def analyze_side(lemma: str, user_pos: str | None, candidate_cell: str) -> Dict[str, object]:\n",
    "    \"\"\"Analyze a side (src or tgt).\"\"\"\n",
    "    cands_raw = sane_list(candidate_cell)\n",
    "    cand_pairs = [parse_candidate_pair(e) for e in cands_raw]\n",
    "    cand_count = len(cand_pairs)\n",
    "\n",
    "    user_pos_norm = normalize_user_pos(user_pos)\n",
    "    exact_match_count = 0\n",
    "    pos_match_count = 0\n",
    "    candidate_pos_set = set()\n",
    "\n",
    "    scored = []\n",
    "    for (lid, lstr) in cand_pairs:\n",
    "        exact = (_norm_text(lstr) == _norm_text(lemma))\n",
    "        if exact:\n",
    "            exact_match_count += 1\n",
    "        cand_pos = extract_pos_from_lexeme_string(lstr)\n",
    "        if cand_pos:\n",
    "            candidate_pos_set.add(cand_pos)\n",
    "        pos_ok = (user_pos_norm and cand_pos and user_pos_norm == cand_pos)\n",
    "        if pos_ok:\n",
    "            pos_match_count += 1\n",
    "\n",
    "        score = 0.0\n",
    "        if exact: score += 5.0\n",
    "        if pos_ok: score += 2.0\n",
    "        score -= abs(len(lstr) - len(lemma)) * 0.01\n",
    "        scored.append((score, lid, lstr))\n",
    "\n",
    "    best_choice_id = best_choice_string = \"\"\n",
    "    best_score = \"\"\n",
    "    top_tie = False\n",
    "\n",
    "    if scored:\n",
    "        scored.sort(key=lambda x: (-x[0], _norm_text(x[2]), x[1]))\n",
    "        best_score_val = scored[0][0]\n",
    "        top = [t for t in scored if t[0] == best_score_val]\n",
    "        top_tie = len(top) > 1\n",
    "        best_choice_id, best_choice_string = top[0][1], top[0][2]\n",
    "        best_score = best_score_val\n",
    "\n",
    "    if cand_count == 0:\n",
    "        reason = \"NO_CANDIDATES\"\n",
    "    elif top_tie:\n",
    "        reason = \"TOP_TIE\"\n",
    "    elif pos_match_count == 0 and exact_match_count == 0 and cand_count > 1:\n",
    "        if len(candidate_pos_set) > 1:\n",
    "            reason = \"AMBIGUOUS_NO_SIGNAL_POS_DIVERSE\"\n",
    "        else:\n",
    "            reason = \"AMBIGUOUS_NO_SIGNAL\"\n",
    "    elif pos_match_count == 0 and user_pos_norm is not None and len(candidate_pos_set) > 1:\n",
    "        reason = \"POS_AMBIGUITY\"\n",
    "    else:\n",
    "        reason = \"OK_OR_WEAK_SIGNAL\"\n",
    "\n",
    "    return {\n",
    "        \"cand_count\": cand_count,\n",
    "        \"exact_match_count\": exact_match_count,\n",
    "        \"pos_match_count\": pos_match_count,\n",
    "        \"candidate_pos_set\": \",\".join(sorted(candidate_pos_set)) if candidate_pos_set else \"\",\n",
    "        \"top_tie\": top_tie,\n",
    "        \"reason\": reason,\n",
    "        \"best_choice_id\": best_choice_id,\n",
    "        \"best_choice_string\": best_choice_string,\n",
    "        \"best_choice_score\": best_score,\n",
    "    }\n",
    "\n",
    "def analyze_file(df: pd.DataFrame, lang_tag: str) -> pd.DataFrame:\n",
    "    \"\"\"Append diagnostics for both sides (src/tgt).\"\"\"\n",
    "    rows = []\n",
    "    n = len(df)\n",
    "    print(f\"[{lang_tag.upper()}] Analyzing {n} rows (progress every {PROGRESS_EVERY}) ...\")\n",
    "    for i, row in enumerate(df.itertuples(index=False), 1):\n",
    "        src_lemma = str(getattr(row, \"src_lemma\"))\n",
    "        tgt_lemma = str(getattr(row, \"tgt_lemma\"))\n",
    "        src_pos   = getattr(row, \"src_pos\", None)\n",
    "        tgt_pos   = getattr(row, \"tgt_pos\", None)\n",
    "\n",
    "        # NaN-safe coercion\n",
    "        if isinstance(src_pos, float) and pd.isna(src_pos): src_pos = None\n",
    "        if isinstance(tgt_pos, float) and pd.isna(tgt_pos): tgt_pos = None\n",
    "\n",
    "        src_cand  = getattr(row, \"src_lexeme_candidates\", \"\")\n",
    "        tgt_cand  = getattr(row, \"tgt_lexeme_candidates\", \"\")\n",
    "\n",
    "        src_diag = analyze_side(src_lemma, src_pos, src_cand)\n",
    "        tgt_diag = analyze_side(tgt_lemma, tgt_pos, tgt_cand)\n",
    "\n",
    "        if src_diag[\"reason\"] == \"NO_CANDIDATES\" and tgt_diag[\"reason\"] == \"NO_CANDIDATES\":\n",
    "            row_reason = \"BOTH_SIDES_NO_CANDIDATES\"\n",
    "        elif src_diag[\"reason\"].startswith(\"AMBIGUOUS\") or tgt_diag[\"reason\"].startswith(\"AMBIGUOUS\"):\n",
    "            row_reason = \"AMBIGUITY\"\n",
    "        elif src_diag[\"reason\"] == \"TOP_TIE\" or tgt_diag[\"reason\"] == \"TOP_TIE\":\n",
    "            row_reason = \"TOP_TIE\"\n",
    "        elif \"POS\" in src_diag[\"reason\"] or \"POS\" in tgt_diag[\"reason\"]:\n",
    "            row_reason = \"POS_MISMATCH_OR_AMBIGUITY\"\n",
    "        else:\n",
    "            row_reason = \"OK_OR_WEAK_SIGNAL\"\n",
    "\n",
    "        base = dict(zip(df.columns, getattr(row, \"_fields\") and row))\n",
    "        base.update({\n",
    "            \"src_cand_count\": src_diag[\"cand_count\"],\n",
    "            \"src_exact_match_count\": src_diag[\"exact_match_count\"],\n",
    "            \"src_pos_match_count\": src_diag[\"pos_match_count\"],\n",
    "            \"src_candidate_pos_set\": src_diag[\"candidate_pos_set\"],\n",
    "            \"src_top_tie\": src_diag[\"top_tie\"],\n",
    "            \"src_reason\": src_diag[\"reason\"],\n",
    "            \"src_best_choice_string\": src_diag[\"best_choice_string\"],\n",
    "            \"src_best_choice_id\": src_diag[\"best_choice_id\"],\n",
    "            \"src_best_choice_score\": src_diag[\"best_choice_score\"],\n",
    "\n",
    "            \"tgt_cand_count\": tgt_diag[\"cand_count\"],\n",
    "            \"tgt_exact_match_count\": tgt_diag[\"exact_match_count\"],\n",
    "            \"tgt_pos_match_count\": tgt_diag[\"pos_match_count\"],\n",
    "            \"tgt_candidate_pos_set\": tgt_diag[\"candidate_pos_set\"],\n",
    "            \"tgt_top_tie\": tgt_diag[\"top_tie\"],\n",
    "            \"tgt_reason\": tgt_diag[\"reason\"],\n",
    "            \"tgt_best_choice_string\": tgt_diag[\"best_choice_string\"],\n",
    "            \"tgt_best_choice_id\": tgt_diag[\"best_choice_id\"],\n",
    "            \"tgt_best_choice_score\": tgt_diag[\"best_choice_score\"],\n",
    "            \"row_reason\": row_reason,\n",
    "        })\n",
    "        rows.append(base)\n",
    "\n",
    "        if i % PROGRESS_EVERY == 0 or i == n:\n",
    "            print(f\"  processed {i}/{n}\")\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def summarize_analyzed(df_an: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Aggregate useful counts for quick overview.\"\"\"\n",
    "    out = []\n",
    "\n",
    "    def add(name, val):\n",
    "        out.append({\"metric\": name, \"count\": int(val)})\n",
    "\n",
    "    add(\"rows\", len(df_an))\n",
    "    add(\"src_no_candidates\", (df_an[\"src_reason\"] == \"NO_CANDIDATES\").sum())\n",
    "    add(\"tgt_no_candidates\", (df_an[\"tgt_reason\"] == \"NO_CANDIDATES\").sum())\n",
    "    add(\"both_sides_no_candidates\", (df_an[\"row_reason\"] == \"BOTH_SIDES_NO_CANDIDATES\").sum())\n",
    "    add(\"row_top_tie\", (df_an[\"row_reason\"] == \"TOP_TIE\").sum())\n",
    "    add(\"row_pos_mismatch_or_ambiguity\", (df_an[\"row_reason\"] == \"POS_MISMATCH_OR_AMBIGUITY\").sum())\n",
    "    add(\"row_ambiguity\", (df_an[\"row_reason\"] == \"AMBIGUITY\").sum())\n",
    "    add(\"row_ok_or_weak\", (df_an[\"row_reason\"] == \"OK_OR_WEAK_SIGNAL\").sum())\n",
    "\n",
    "    for k in [\"src_cand_count\", \"tgt_cand_count\"]:\n",
    "        vc = df_an[k].value_counts(dropna=False).sort_index()\n",
    "        for num, cnt in vc.items():\n",
    "            out.append({\"metric\": f\"{k}=={num}\", \"count\": int(cnt)})\n",
    "\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "\n",
    "def run_analysis_for_language(xx: str):\n",
    "    print(f\"\\n=== {xx.upper()} diagnostics ===\")\n",
    "    for which in [\"unresolved\", \"resolved\"]:\n",
    "        in_path  = os.path.join(BASE, INPUTS[which].format(xx=xx))\n",
    "        out_path = os.path.join(BASE, OUTPUTS[which].format(xx=xx))\n",
    "\n",
    "        if not os.path.exists(in_path):\n",
    "            print(f\"  [SKIP] {which}: {in_path} (not found)\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  [LOAD] {which}: {in_path}\")\n",
    "        df = pd.read_csv(in_path)\n",
    "\n",
    "        for col in [\"src_lexeme_candidates\", \"tgt_lexeme_candidates\"]:\n",
    "            if col not in df.columns:\n",
    "                df[col] = \"\"\n",
    "\n",
    "        analyzed = analyze_file(df, xx)\n",
    "        analyzed.to_csv(out_path, index=False)\n",
    "        print(f\"  [SAVE] {which} analyzed → {os.path.basename(out_path)}  ({len(analyzed)} rows)\")\n",
    "\n",
    "    parts = []\n",
    "    for which in [\"unresolved\", \"resolved\"]:\n",
    "        p = os.path.join(BASE, OUTPUTS[which].format(xx=xx))\n",
    "        if os.path.exists(p):\n",
    "            df_an = pd.read_csv(p)\n",
    "            s = summarize_analyzed(df_an)\n",
    "            s.insert(0, \"set\", which)\n",
    "            parts.append(s)\n",
    "    if parts:\n",
    "        summary = pd.concat(parts, ignore_index=True)\n",
    "        sum_path = os.path.join(BASE, SUMMARY_TPL.format(xx=xx))\n",
    "        summary.to_csv(sum_path, index=False)\n",
    "        print(f\"  [SUMMARY] wrote {os.path.basename(sum_path)}\")\n",
    "\n",
    "for xx in LANGS:\n",
    "    run_analysis_for_language(xx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a48052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ES ===\n",
      "[load] en_es_prefrel_union.csv rows=1,339\n",
      "[duo] aggregating for en->es (src)\n",
      "  [duo en->es] chunk 3: total=750,000, kept=303,176, lemmas=1,396\n",
      "  [duo en->es] chunk 6: total=1,500,000, kept=587,825, lemmas=1,404\n",
      "  [duo en->es] chunk 9: total=2,250,000, kept=850,578, lemmas=1,405\n",
      "  [duo en->es] chunk 12: total=3,000,000, kept=1,139,825, lemmas=1,407\n",
      "  [duo en->es] chunk 15: total=3,750,000, kept=1,428,928, lemmas=1,407\n",
      "  [duo en->es] chunk 18: total=4,500,000, kept=1,714,872, lemmas=1,409\n",
      "  [duo en->es] chunk 21: total=5,250,000, kept=2,002,942, lemmas=1,410\n",
      "  [duo en->es] chunk 24: total=6,000,000, kept=2,294,563, lemmas=1,410\n",
      "  [duo en->es] chunk 27: total=6,750,000, kept=2,583,561, lemmas=1,411\n",
      "  [duo en->es] chunk 30: total=7,500,000, kept=2,862,486, lemmas=1,411\n",
      "  [duo en->es] chunk 33: total=8,250,000, kept=3,138,855, lemmas=1,411\n",
      "  [duo en->es] chunk 36: total=9,000,000, kept=3,434,592, lemmas=1,411\n",
      "  [duo en->es] chunk 39: total=9,527,895, kept=3,641,179, lemmas=1,411\n",
      "  [duo en->es] done: kept=3,641,179, lemmas=1,411\n",
      "[duo] aggregating for es->en (tgt)\n",
      "  [duo es->en] chunk 3: total=750,000, kept=263,340, lemmas=1,555\n",
      "  [duo es->en] chunk 6: total=1,500,000, kept=536,671, lemmas=1,659\n",
      "  [duo es->en] chunk 9: total=2,250,000, kept=817,347, lemmas=1,701\n",
      "  [duo es->en] chunk 12: total=3,000,000, kept=1,085,962, lemmas=1,713\n",
      "  [duo es->en] chunk 15: total=3,750,000, kept=1,348,360, lemmas=1,718\n",
      "  [duo es->en] chunk 18: total=4,500,000, kept=1,621,915, lemmas=1,720\n",
      "  [duo es->en] chunk 21: total=5,250,000, kept=1,878,991, lemmas=1,722\n",
      "  [duo es->en] chunk 24: total=6,000,000, kept=2,141,095, lemmas=1,725\n",
      "  [duo es->en] chunk 27: total=6,750,000, kept=2,407,262, lemmas=1,726\n",
      "  [duo es->en] chunk 30: total=7,500,000, kept=2,680,623, lemmas=1,728\n",
      "  [duo es->en] chunk 33: total=8,250,000, kept=2,956,466, lemmas=1,729\n",
      "  [duo es->en] chunk 36: total=9,000,000, kept=3,220,683, lemmas=1,731\n",
      "  [duo es->en] chunk 39: total=9,527,895, kept=3,407,689, lemmas=1,731\n",
      "  [duo es->en] done: kept=3,407,689, lemmas=1,731\n",
      "  [gram] processed 500/1339 rows\n",
      "  [gram] processed 1000/1339 rows\n",
      "  [gram] processed 1339/1339 rows\n",
      "[write] en_es_prefrel_lemma_hf.csv rows=1,339\n",
      "  stats:\n",
      "   - rows with src_median_hf: 1338\n",
      "   - rows with tgt_median_hf: 1339\n",
      "   - grammatical_conflicts distribution:\n",
      "grammatical_conflicts\n",
      "gender_number_forms    1099\n",
      "verb_forms_others       107\n",
      "no_conflicts            100\n",
      "gender_forms             15\n",
      "verb_forms               13\n",
      "number_forms              5\n",
      "\n",
      "=== IT ===\n",
      "[load] en_it_prefrel_union.csv rows=962\n",
      "[duo] aggregating for en->it (src)\n",
      "  [duo en->it] chunk 3: total=750,000, kept=31,024, lemmas=995\n",
      "  [duo en->it] chunk 6: total=1,500,000, kept=61,938, lemmas=1,170\n",
      "  [duo en->it] chunk 9: total=2,250,000, kept=93,994, lemmas=1,257\n",
      "  [duo en->it] chunk 12: total=3,000,000, kept=128,174, lemmas=1,305\n",
      "  [duo en->it] chunk 15: total=3,750,000, kept=158,002, lemmas=1,360\n",
      "  [duo en->it] chunk 18: total=4,500,000, kept=184,280, lemmas=1,364\n",
      "  [duo en->it] chunk 21: total=5,250,000, kept=222,638, lemmas=1,375\n",
      "  [duo en->it] chunk 24: total=6,000,000, kept=260,329, lemmas=1,392\n",
      "  [duo en->it] chunk 27: total=6,750,000, kept=296,426, lemmas=1,396\n",
      "  [duo en->it] chunk 30: total=7,500,000, kept=331,775, lemmas=1,402\n",
      "  [duo en->it] chunk 33: total=8,250,000, kept=368,805, lemmas=1,405\n",
      "  [duo en->it] chunk 36: total=9,000,000, kept=403,874, lemmas=1,405\n",
      "  [duo en->it] chunk 39: total=9,527,895, kept=424,152, lemmas=1,405\n",
      "  [duo en->it] done: kept=424,152, lemmas=1,405\n",
      "[duo] aggregating for it->en (tgt)\n",
      "  [duo it->en] chunk 3: total=750,000, kept=54,956, lemmas=951\n",
      "  [duo it->en] chunk 6: total=1,500,000, kept=120,020, lemmas=1,020\n",
      "  [duo it->en] chunk 9: total=2,250,000, kept=192,956, lemmas=1,095\n",
      "  [duo it->en] chunk 12: total=3,000,000, kept=257,884, lemmas=1,101\n",
      "  [duo it->en] chunk 15: total=3,750,000, kept=321,912, lemmas=1,106\n",
      "  [duo it->en] chunk 18: total=4,500,000, kept=384,683, lemmas=1,117\n",
      "  [duo it->en] chunk 21: total=5,250,000, kept=443,606, lemmas=1,120\n",
      "  [duo it->en] chunk 24: total=6,000,000, kept=503,364, lemmas=1,171\n",
      "  [duo it->en] chunk 27: total=6,750,000, kept=565,651, lemmas=1,183\n",
      "  [duo it->en] chunk 30: total=7,500,000, kept=628,516, lemmas=1,189\n",
      "  [duo it->en] chunk 33: total=8,250,000, kept=690,678, lemmas=1,270\n",
      "  [duo it->en] chunk 36: total=9,000,000, kept=753,787, lemmas=1,305\n",
      "  [duo it->en] chunk 39: total=9,527,895, kept=793,935, lemmas=1,358\n",
      "  [duo it->en] done: kept=793,935, lemmas=1,358\n",
      "  [gram] processed 500/962 rows\n",
      "  [gram] processed 962/962 rows\n",
      "[write] en_it_prefrel_lemma_hf.csv rows=962\n",
      "  stats:\n",
      "   - rows with src_median_hf: 959\n",
      "   - rows with tgt_median_hf: 962\n",
      "   - grammatical_conflicts distribution:\n",
      "grammatical_conflicts\n",
      "gender_number_forms    584\n",
      "no_conflicts           145\n",
      "gender_forms            97\n",
      "verb_forms_others       85\n",
      "verb_forms              28\n",
      "number_forms            23\n",
      "\n",
      "=== PT ===\n",
      "[load] en_pt_prefrel_union.csv rows=1,150\n",
      "[duo] aggregating for en->pt (src)\n",
      "  [duo en->pt] chunk 3: total=750,000, kept=74,382, lemmas=1,088\n",
      "  [duo en->pt] chunk 6: total=1,500,000, kept=146,583, lemmas=1,251\n",
      "  [duo en->pt] chunk 9: total=2,250,000, kept=220,438, lemmas=1,289\n",
      "  [duo en->pt] chunk 12: total=3,000,000, kept=291,392, lemmas=1,350\n",
      "  [duo en->pt] chunk 15: total=3,750,000, kept=368,975, lemmas=1,357\n",
      "  [duo en->pt] chunk 18: total=4,500,000, kept=447,149, lemmas=1,391\n",
      "  [duo en->pt] chunk 21: total=5,250,000, kept=530,782, lemmas=1,403\n",
      "  [duo en->pt] chunk 24: total=6,000,000, kept=604,507, lemmas=1,405\n",
      "  [duo en->pt] chunk 27: total=6,750,000, kept=677,680, lemmas=1,406\n",
      "  [duo en->pt] chunk 30: total=7,500,000, kept=752,822, lemmas=1,406\n",
      "  [duo en->pt] chunk 33: total=8,250,000, kept=823,012, lemmas=1,406\n",
      "  [duo en->pt] chunk 36: total=9,000,000, kept=894,212, lemmas=1,406\n",
      "  [duo en->pt] chunk 39: total=9,527,895, kept=949,460, lemmas=1,406\n",
      "  [duo en->pt] done: kept=949,460, lemmas=1,406\n",
      "[duo] aggregating for pt->en (tgt)\n",
      "  [duo pt->en] chunk 3: total=750,000, kept=23,122, lemmas=878\n",
      "  [duo pt->en] chunk 6: total=1,500,000, kept=46,963, lemmas=1,020\n",
      "  [duo pt->en] chunk 9: total=2,250,000, kept=74,687, lemmas=1,151\n",
      "  [duo pt->en] chunk 12: total=3,000,000, kept=96,763, lemmas=1,248\n",
      "  [duo pt->en] chunk 15: total=3,750,000, kept=123,823, lemmas=1,320\n",
      "  [duo pt->en] chunk 18: total=4,500,000, kept=147,101, lemmas=1,383\n",
      "  [duo pt->en] chunk 21: total=5,250,000, kept=171,041, lemmas=1,440\n",
      "  [duo pt->en] chunk 24: total=6,000,000, kept=196,142, lemmas=1,498\n",
      "  [duo pt->en] chunk 27: total=6,750,000, kept=219,420, lemmas=1,531\n",
      "  [duo pt->en] chunk 30: total=7,500,000, kept=243,778, lemmas=1,555\n",
      "  [duo pt->en] chunk 33: total=8,250,000, kept=272,184, lemmas=1,574\n",
      "  [duo pt->en] chunk 36: total=9,000,000, kept=292,852, lemmas=1,580\n",
      "  [duo pt->en] chunk 39: total=9,527,895, kept=311,480, lemmas=1,600\n",
      "  [duo pt->en] done: kept=311,480, lemmas=1,600\n",
      "  [gram] processed 500/1150 rows\n",
      "  [gram] processed 1000/1150 rows\n",
      "  [gram] processed 1150/1150 rows\n",
      "[write] en_pt_prefrel_lemma_hf.csv rows=1,150\n",
      "  stats:\n",
      "   - rows with src_median_hf: 1145\n",
      "   - rows with tgt_median_hf: 1150\n",
      "   - grammatical_conflicts distribution:\n",
      "grammatical_conflicts\n",
      "gender_number_forms    712\n",
      "verb_forms_others      128\n",
      "no_conflicts           127\n",
      "gender_forms            85\n",
      "verb_forms              51\n",
      "number_forms            47\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Set, Tuple, List\n",
    "\n",
    "\n",
    "BASE = \".\"                       \n",
    "DUO_PATH = os.path.join(BASE, \"duo.csv\")\n",
    "LANGS = [\"es\", \"it\", \"pt\"]       \n",
    "PREFREL_TPL = \"en_{xx}_prefrel_union.csv\"\n",
    "OUT_TPL = \"en_{xx}_prefrel_lemma_hf.csv\"\n",
    "\n",
    "CHUNKSIZE = 250_000              \n",
    "PROGRESS_EVERY = 3               \n",
    "\n",
    "\n",
    "def load_prefrel(xx: str) -> pd.DataFrame:\n",
    "    path = os.path.join(BASE, PREFREL_TPL.format(xx=xx))\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Missing prefrel file: {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    need = [\"src_lemma\", \"tgt_lemma\", \"src_pos\", \"tgt_pos\"]\n",
    "    missing = [c for c in need if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{os.path.basename(path)} missing required columns: {missing}\")\n",
    "    \n",
    "    return df[need].copy()\n",
    "\n",
    "def meaning_conflict_flags(prefrel: pd.DataFrame) -> pd.Series:\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    src2tgt_count = prefrel.groupby(\"src_lemma\")[\"tgt_lemma\"].nunique()\n",
    "    tgt2src_count = prefrel.groupby(\"tgt_lemma\")[\"src_lemma\"].nunique()\n",
    "    return (prefrel[\"src_lemma\"].map(src2tgt_count).fillna(0) > 1) | \\\n",
    "           (prefrel[\"tgt_lemma\"].map(tgt2src_count).fillna(0) > 1)\n",
    "\n",
    "\n",
    "_GENDER_PAT = re.compile(\n",
    "    r\"\\b(masc(?:\\.|uline)?|fem(?:\\.|inine)?|masch(?:ile)?|femm(?:inile)?|\"\n",
    "    r\"masculino|femenino|feminino|m\\.?|f\\.?|m/f|mf|invar\\.?|invariabile|invariable)\\b\",\n",
    "    re.I,\n",
    ")\n",
    "_NUMBER_PAT = re.compile(\n",
    "    r\"\\b(pl(?:\\.|ural)?|sg(?:\\.|ing)?|plur\\.?|sing\\.?)\\b\",\n",
    "    re.I,\n",
    ")\n",
    "\n",
    "def _looks_gender_alternation(a: str, b: str) -> bool:\n",
    "    \n",
    "    a_ = a.strip().lower()\n",
    "    b_ = b.strip().lower()\n",
    "    if len(a_) < 2 or len(b_) < 2:\n",
    "        return False\n",
    "    \n",
    "    if a_[:-1] == b_[:-1] and {a_[-1], b_[-1]} in ({\"o\",\"a\"}, {\"i\",\"e\"}):\n",
    "        return True\n",
    "    \n",
    "    if (a_.endswith(\"ore\") and b_.endswith(\"rice\")) or (a_.endswith(\"rice\") and b_.endswith(\"ore\")):\n",
    "        return True\n",
    "    \n",
    "    if a_.endswith(\"essa\") and (b_ == a_[:-4] or b_.endswith(a_[:-4])):\n",
    "        return True\n",
    "    if b_.endswith(\"essa\") and (a_ == b_[:-4] or a_.endswith(b_[:-4])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def classify_grammatical(src_pos: str, tgt_pos: str,\n",
    "                         src_forms: Set[str], tgt_forms: Set[str]) -> str:\n",
    "    \n",
    "    forms = set()\n",
    "    if src_forms:\n",
    "        forms.update({str(s) for s in src_forms if isinstance(s, (str, bytes))})\n",
    "    if tgt_forms:\n",
    "        forms.update({str(s) for s in tgt_forms if isinstance(s, (str, bytes))})\n",
    "\n",
    "    \n",
    "    if len(forms) <= 1:\n",
    "        return \"no_conflicts\"\n",
    "\n",
    "    \n",
    "    has_verb_pos = False\n",
    "    if isinstance(src_pos, str) and src_pos.lower().startswith(\"v\"):\n",
    "        has_verb_pos = True\n",
    "    if isinstance(tgt_pos, str) and tgt_pos.lower().startswith(\"v\"):\n",
    "        has_verb_pos = True\n",
    "\n",
    "    joined = \" || \".join(forms)\n",
    "    gender_flag = bool(_GENDER_PAT.search(joined))\n",
    "    number_flag = bool(_NUMBER_PAT.search(joined))\n",
    "\n",
    "    \n",
    "    if not gender_flag:\n",
    "        pos_nadj = False\n",
    "        if isinstance(src_pos, str) and src_pos.lower().startswith((\"n\",\"a\")):\n",
    "            pos_nadj = True\n",
    "        if isinstance(tgt_pos, str) and tgt_pos.lower().startswith((\"n\",\"a\")):\n",
    "            pos_nadj = True\n",
    "        if pos_nadj:\n",
    "            fs = sorted(forms)\n",
    "            for i in range(len(fs)):\n",
    "                for j in range(i+1, len(fs)):\n",
    "                    if _looks_gender_alternation(fs[i], fs[j]):\n",
    "                        gender_flag = True\n",
    "                        break\n",
    "                if gender_flag:\n",
    "                    break\n",
    "\n",
    "    \n",
    "    if has_verb_pos:\n",
    "        if not gender_flag and not number_flag:\n",
    "            return \"verb_forms\"\n",
    "        else:\n",
    "            return \"verb_forms_others\"\n",
    "\n",
    "    if gender_flag and number_flag:\n",
    "        return \"gender_number_forms\"\n",
    "    if gender_flag:\n",
    "        return \"gender_forms\"\n",
    "    if number_flag:\n",
    "        return \"number_forms\"\n",
    "    return \"no_conflicts\"\n",
    "\n",
    "\n",
    "def aggregate_duo_for_direction(\n",
    "    duo_path: str,\n",
    "    learning_lang: str,\n",
    "    ui_lang: str,\n",
    ") -> Tuple[Dict[str, float], Dict[str, int], Dict[str, Set[str]]]:\n",
    "    \n",
    "\n",
    "\n",
    "    if not os.path.exists(duo_path):\n",
    "        raise FileNotFoundError(f\"duo.csv not found at: {duo_path}\")\n",
    "\n",
    "    need = [\"lemma\", \"learning_language\", \"ui_language\", \"lexeme_id\", \"lexeme_string\", \"half_life\"]\n",
    "\n",
    "    hf_values: Dict[str, List[float]] = defaultdict(list)\n",
    "    lexeme_ids: Dict[str, Set[str]] = defaultdict(set)\n",
    "    lexeme_strings: Dict[str, Set[str]] = defaultdict(set)\n",
    "\n",
    "    chunk_i = 0\n",
    "    kept_rows = 0\n",
    "    total_rows = 0\n",
    "\n",
    "    for chunk in pd.read_csv(duo_path, usecols=need, chunksize=CHUNKSIZE):\n",
    "        chunk_i += 1\n",
    "        total_rows += len(chunk)\n",
    "\n",
    "        sub = chunk[(chunk[\"learning_language\"] == learning_lang) &\n",
    "                    (chunk[\"ui_language\"] == ui_lang)]\n",
    "        if sub.empty:\n",
    "            if chunk_i % PROGRESS_EVERY == 0:\n",
    "                print(f\"  [duo {learning_lang}->{ui_lang}] chunk {chunk_i}: \"\n",
    "                      f\"total={total_rows:,}, kept={kept_rows:,}, lemmas={len(hf_values):,}\")\n",
    "            continue\n",
    "        kept_rows += len(sub)\n",
    "\n",
    "        for lemma, lid, lstr, hf in sub[[\"lemma\", \"lexeme_id\", \"lexeme_string\", \"half_life\"]].itertuples(index=False):\n",
    "            if pd.isna(lemma) or pd.isna(hf):\n",
    "                continue\n",
    "            hf_values[str(lemma)].append(float(hf))\n",
    "            if not pd.isna(lid):\n",
    "                lexeme_ids[str(lemma)].add(str(lid))\n",
    "            if not pd.isna(lstr):\n",
    "                lexeme_strings[str(lemma)].add(str(lstr))\n",
    "\n",
    "        if chunk_i % PROGRESS_EVERY == 0:\n",
    "            print(f\"  [duo {learning_lang}->{ui_lang}] chunk {chunk_i}: \"\n",
    "                  f\"total={total_rows:,}, kept={kept_rows:,}, lemmas={len(hf_values):,}\")\n",
    "\n",
    "    import numpy as np\n",
    "    medians = {lemma: float(np.median(vals)) for lemma, vals in hf_values.items()}\n",
    "    counts = {lemma: len(ids) for lemma, ids in lexeme_ids.items()}\n",
    "\n",
    "    print(f\"  [duo {learning_lang}->{ui_lang}] done: kept={kept_rows:,}, lemmas={len(medians):,}\")\n",
    "    return medians, counts, lexeme_strings\n",
    "\n",
    "\n",
    "def process_language(xx: str):\n",
    "    print(f\"\\n=== {xx.upper()} ===\")\n",
    "    prefrel = load_prefrel(xx)\n",
    "    print(f\"[load] {PREFREL_TPL.format(xx=xx)} rows={len(prefrel):,}\")\n",
    "\n",
    "    meaning_mask = meaning_conflict_flags(prefrel)\n",
    "\n",
    "    forward = (\"en\", xx)  \n",
    "    reverse = (xx, \"en\")  \n",
    "\n",
    "    print(f\"[duo] aggregating for {forward[0]}->{forward[1]} (src)\")\n",
    "    src_median_hf, src_candidates_count, src_forms = aggregate_duo_for_direction(DUO_PATH, *forward)\n",
    "\n",
    "    print(f\"[duo] aggregating for {reverse[0]}->{reverse[1]} (tgt)\")\n",
    "    tgt_median_hf, tgt_candidates_count, tgt_forms = aggregate_duo_for_direction(DUO_PATH, *reverse)\n",
    "\n",
    "    out = prefrel.copy()\n",
    "    out[\"src_median_hf\"] = out[\"src_lemma\"].map(src_median_hf)\n",
    "    out[\"tgt_median_hf\"] = out[\"tgt_lemma\"].map(tgt_median_hf)\n",
    "    out[\"src_candidates_count\"] = out[\"src_lemma\"].map(src_candidates_count).fillna(0).astype(int)\n",
    "    out[\"tgt_candidates_count\"] = out[\"tgt_lemma\"].map(tgt_candidates_count).fillna(0).astype(int)\n",
    "\n",
    "    \n",
    "    grams = []\n",
    "    for i, r in out.iterrows():\n",
    "        src_forms_set = src_forms.get(r[\"src_lemma\"], set())\n",
    "        tgt_forms_set = tgt_forms.get(r[\"tgt_lemma\"], set())\n",
    "        label = classify_grammatical(r[\"src_pos\"], r[\"tgt_pos\"], src_forms_set, tgt_forms_set)\n",
    "        grams.append(label)\n",
    "        if (i + 1) % 500 == 0 or (i + 1) == len(out):\n",
    "            print(f\"  [gram] processed {i+1}/{len(out)} rows\")\n",
    "    out[\"grammatical_conflicts\"] = grams\n",
    "\n",
    "    \n",
    "    out[\"meaning_conflicts\"] = meaning_mask.values\n",
    "\n",
    "    \n",
    "    out_path = os.path.join(BASE, OUT_TPL.format(xx=xx))\n",
    "    out.to_csv(out_path, index=False)\n",
    "    print(f\"[write] {os.path.basename(out_path)} rows={len(out):,}\")\n",
    "    print(\"  stats:\")\n",
    "    print(\"   - rows with src_median_hf:\", int(out[\"src_median_hf\"].notna().sum()))\n",
    "    print(\"   - rows with tgt_median_hf:\", int(out[\"tgt_median_hf\"].notna().sum()))\n",
    "    print(\"   - grammatical_conflicts distribution:\")\n",
    "    print(out[\"grammatical_conflicts\"].value_counts(dropna=False).to_string())\n",
    "\n",
    "\n",
    "for xx in LANGS:\n",
    "    process_language(xx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9137ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ES ===\n",
      "  loaded 1,339 rows\n",
      "  saved → en_es_prefrel_lemma_hf.csv\n",
      "  preview:\n",
      "src_median_hf tgt_median_hf\n",
      " 3.028902e+06  6.557191e+07\n",
      " 2.922286e+06  1.144294e+09\n",
      " 5.649768e+08  6.831733e+08\n",
      " 3.412588e+09  2.166358e+09\n",
      " 5.750824e+08  1.491533e+09\n",
      "\n",
      "=== IT ===\n",
      "  loaded 962 rows\n",
      "  saved → en_it_prefrel_lemma_hf.csv\n",
      "  preview:\n",
      "src_median_hf tgt_median_hf\n",
      " 4.110157e+06  1.841808e+08\n",
      " 2.714783e+08  5.215568e+08\n",
      " 2.714783e+08  3.346139e+08\n",
      " 6.456620e+08  3.339416e+08\n",
      " 6.456620e+08  1.463507e+07\n",
      "\n",
      "=== PT ===\n",
      "  loaded 1,150 rows\n",
      "  saved → en_pt_prefrel_lemma_hf.csv\n",
      "  preview:\n",
      "src_median_hf tgt_median_hf\n",
      " 2.959590e+06  5.720500e+08\n",
      " 1.777244e+08  4.082641e+08\n",
      " 1.777244e+08  7.152921e+06\n",
      " 2.278171e+09  2.451539e+07\n",
      " 2.052147e+09  6.926066e+08\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE = \".\"  \n",
    "LANGS = [\"es\", \"it\", \"pt\"]\n",
    "IN_TPL = \"en_{xx}_prefrel_lemma_hf.csv\"\n",
    "OUT_TPL = \"en_{xx}_prefrel_lemma_hf.csv\"  \n",
    "\n",
    "def fmt_sci(val):\n",
    "    if pd.isna(val):\n",
    "        return \"\"\n",
    "    try:\n",
    "        return f\"{float(val):.6e}\"\n",
    "    except Exception:\n",
    "        \n",
    "        try:\n",
    "            return f\"{float(pd.to_numeric(val, errors='coerce')):.6e}\"\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "for xx in LANGS:\n",
    "    in_path = os.path.join(BASE, IN_TPL.format(xx=xx))\n",
    "    out_path = os.path.join(BASE, OUT_TPL.format(xx=xx))\n",
    "\n",
    "    if not os.path.exists(in_path):\n",
    "        print(f\"[SKIP] {in_path} not found\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n=== {xx.upper()} ===\")\n",
    "    df = pd.read_csv(in_path)\n",
    "    print(f\"  loaded {len(df):,} rows\")\n",
    "\n",
    "    \n",
    "    df.rename(columns={\n",
    "        \"src_candidates_count\": \"src_lexeme_count\",\n",
    "        \"tgt_candidates_count\": \"tgt_lexeme_count\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    \n",
    "    for col in [\"src_median_hf\", \"tgt_median_hf\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            df[col] = df[col].map(fmt_sci)\n",
    "        else:\n",
    "            print(f\"  [WARN] column missing: {col}\")\n",
    "\n",
    "    \n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"  saved → {os.path.basename(out_path)}\")\n",
    "\n",
    "    \n",
    "    cols = [c for c in [\"src_median_hf\", \"tgt_median_hf\"] if c in df.columns]\n",
    "    if cols:\n",
    "        print(\"  preview:\")\n",
    "        print(df[cols].head(5).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
